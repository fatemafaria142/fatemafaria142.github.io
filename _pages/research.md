---
layout: archive
title: "Research"
permalink: /research/
author_profile: true
---
<p style="text-align:justify; color:black; font-family:Georgia">
My research delves into the realms of 
</p> 


## 1. Multimodal Deep Learning
<p style="text-align:justify; color:black; font-family:Georgia">
Multimodal deep learning is a method that improves understanding by combining images and text. This approach uses three main techniques: early fusion, late fusion, and intermediate fusion. In early fusion, raw images and text are combined into a single input before the model processes them. This allows the model to learn a shared representation, but it can also make it sensitive to noise from either the images or the text. Late fusion works differently. Here, images and text are processed separately using different models. The results are combined later on. This method is flexible and allows each model to be optimized independently, but it might miss important connections between the two modalities that could improve performance. Intermediate fusion is a middle ground. It combines features from images and text at different stages of processing. This way, it keeps the unique qualities of each type of data while also sharing useful information between them. A major challenge in using multimodal deep learning for the Bangla language is the lack of annotated datasets that pair images and text. Most existing datasets are not diverse enough, which can lead to models that don't work well in different situations. There is still a significant need for high-quality, labeled image-text datasets in Bangla. The Bangla language has unique features, such as context, idiomatic expressions, and cultural references, which make multimodal learning more complex. Common text processing techniques often struggle to capture these nuances, making it hard to integrate text with images effectively. Different applications, like detecting fake news or identifying disasters, require specific ways to combine data and train models. For example, fake news detection needs to focus on language and feelings, while disaster identification relies on visual information and real-time data. The lack of specialized multimodal models for Bangla makes it hard to improve performance in these areas. Without custom models, it's difficult to solve the unique challenges that Bangla speakers face. To make the most of multimodal learning, we need to create models that meet the specific needs of these applications in the Bangla context.
</p>  

### Related Paper:
+ <span style="font-family:Trebuchet MS; color:black;"><span style="color:#6E2C00">Uddessho: An Extensive Benchmark Dataset for Multimodal Author Intent Classification in Low-Resource Bangla Language</span>. Fatema Tuj Johora Faria, Mukaffi Bin Moin, Md. Mahfuzur Rahman, Md Morshed Alam Shanto, Asif Iftekher Fahim and Md. Moinul Hoque. <span style="color:green;"><em> Accepted in 18th International Conference on Information Technology and Applications (ICITA 2024)</em></span>. [[PDF]](https://arxiv.org/pdf/2409.09504)</span>   

+ <span style="font-family:Trebuchet MS; color:black;"><span style="color:#6E2C00">BanglaCalamityMMD: A Comprehensive Benchmark Dataset
for Multimodal Disaster Identification in the Low-Resource Bangla Language
</span>. atema Tuj Johora Faria, Mukaffi Bin Moin, Busra Kamal Rafa, Swarnajit Saha, Md. Mahfuzur Rahman, Khan Md Hasib, and M. F. Mridha. <span style="color:green;"><em> Under Review in International Journal of Disaster Risk Reduction</em></span>.</span>  


+ <span style="font-family:Trebuchet MS; color:black;"><span style="color:#6E2C00">MultiBanFakeDetect: Integrating Advanced Fusion Techniques for Multimodal Detection of Bangla Fake News in Under-Resourced Contexts </span>. Fatema Tuj Johora Faria, Mukaffi Bin Moin, Md Arafat Alam Khandaker, Niful Islam, Khan Md Hasib, Md Saddam Hossain Mukta, and M. F. Mridha. <span style="color:green;"><em> Under Review in Engineering Applications of Artificial Intelligence</em></span>.</span>  


+ <span style="font-family:Trebuchet MS; color:black;"><span style="color:#6E2C00">BanglaMemeEvidence: A Multimodal Benchmark Dataset for Explanatory Evidence Detection in Bengali Memes</span>. Fatema Tuj Johora Faria, Mukaffi Bin Moin, Asif Iftekher Fahim, Pronay Debnath, and Faisal Muhammad Shah. <span style="color:green;"><em> Submitted to an A* Rank Conference</em></span>.</span>  


## 2. Sentiment Analysis and Hate Speech Detection in Social Media

## 3. Natural Language Inference 

## 4. Text Generation in Bengali

## 5. Image-to-Text Generation


## 6. Explainable AI in Medical Image Analysis


## 7. Machine Translation and Regional Dialect Detection


## 8. Natural Language Processing for Medical Question Answering

## 9. Generative Adversarial Networks in Agriculture


## 10. Computer Vision Applications in Agriculture