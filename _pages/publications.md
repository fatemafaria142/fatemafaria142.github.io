---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

<span style="color:black; font-family:Georgia;">Most recent publication updates can be found on my <a style ="color:#800080;" href="https://scholar.google.com/citations?user=LEken_4AAAAJ&hl=en"><em>[Google Scholar]</em></a> profile.</span><br>
<span style="color:black; font-family:Georgia;">[*] denotes equal contribution</span>

## 2024
--------- 

<!-- [[<span style ="color:red"><font size="3">Code</font></span>](https://github.com/fatemafaria142/MultiBanFakeDetect-An-Extensive-Benchmark-Dataset-for-Multimodal-Bangla-Fake-News-Detection)] [[<span style ="color:red"><font size="3">Dataset</font></span>](https://data.mendeley.com/datasets/k5pbz9795f/1)] -->

<!-- Paper 10 -->
ðŸ“Œ <span style="color:blue;font-family:Trebuchet MS;">**MultiBanFakeDetect: Integrating Advanced Fusion Techniques for Multimodal Detection of Bangla Fake News in Under-Resourced Contexts** </span> (<span style="color:red"><strong>Q1</strong></span>)<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Authors</strong>: <strong style="color:green">Fatema Tuj Johora Faria</strong>, Mukaffi Bin Moin, Zayeed Hasan, Md Arafat Alam Khandaker, Niful Islam, Khan Md Hasib, Md Saddam Hossain Mukta, and M. F. Mridha</font>
</span>
<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Journal:</strong><em> Under Review in Engineering Applications of Artificial Intelligence </em></font>  ([Engineering Applications of Artificial Intelligence](https://www.sciencedirect.com/journal/engineering-applications-of-artificial-intelligence))
</span>
<br>
[[<span style ="color:red"><font size="3">Code</font></span>](https://github.com/fatemafaria142/MultiBanFakeDetect-An-Extensive-Benchmark-Dataset-for-Multimodal-Bangla-Fake-News-Detection)] [[<span style ="color:red"><font size="3">Dataset</font></span>](https://data.mendeley.com/datasets/k5pbz9795f/1)]



<!-- Paper 09 -->
ðŸ“Œ <span style="color:blue;font-family:Trebuchet MS;">**BanglaCalamityMMD: A Comprehensive Benchmark Dataset for Multimodal Disaster Identification in the Low-Resource Bangla Language** </span>  (<span style="color:red"><strong>Q1</strong></span>)<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Authors</strong>: <strong style="color:green">Fatema Tuj Johora Faria</strong>, Mukaffi Bin Moin, Busra Kamal Rafa, Swarnajit Saha, Md. Mahfuzur Rahman, Khan Md Hasib, and M. F. Mridha</font>
</span>
<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Journal:</strong><em> Under Review in International Journal of Disaster Risk Reduction </em></font>  ([Disaster Risk Reduction](https://www.sciencedirect.com/journal/international-journal-of-disaster-risk-reduction))
</span>
<br>
[[<span style ="color:red"><font size="3">Code</font></span>](https://github.com/Mukaffi28/BanglaCalamityMMD-A-Comprehensive-Benchmark-Dataset-for-Multimodal-Disaster-Identification)] [[<span style ="color:red"><font size="3">Dataset</font></span>](https://data.mendeley.com/datasets/7dggbjn5sd/1)] 

<div id="" class="bib" style="display:none;">
	<pre>
	</pre>
</div>

<div id="" class="abstract" style="display:none;">
	<p style="text-align:justify; color:black;font-family:Monaco;"> 
		<font size="3">
		</font>
	</p>
</div>

<br>

<!-- Paper 11 -->
ðŸ“Œ <span style="color:blue;font-family:Trebuchet MS;">**Investigating the Predominance of Large Language Models in Low-Resource Bangla Language Over Transformer Models for Hate Speech Detection: A Comparative Analysis**</span><br>
<span style="color:black;font-family:Georgia"> 
	<font size="3"><strong>Authors</strong>: <strong style="color:green">Fatema Tuj Johora Faria</strong>, Laith H. Baniata, Hayder Albayati, Mohammad H. Baniata, Majdi Alsaaideh, Mohannad A. Khair, and Sangwoo Kang</font>
</span>
<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Journal:</strong><em> Under Review in MDPI Electronics </em></font>  ([Electronics](https://www.mdpi.com/journal/electronics))
</span>
<br>

<!-- Paper 08 -->
ðŸ“Œ <span style="color:blue;font-family:Trebuchet MS;">**BanglaMemeEvidence: A Multimodal Benchmark Dataset for Explanatory Evidence Detection in Bengali MemesBanglaMemeEvidence: A Multimodal Benchmark Dataset for Explanatory Evidence Detection in Bengali Memes**</span><br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Authors</strong>: <strong style="color:green">Fatema Tuj Johora Faria</strong>, Mukaffi Bin Moin, Asif Iftekher Fahim, Pronay Debnath, and Faisal Muhammad Shah.</font>
</span>
<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Conference:</strong><em> Submitted to an A* Rank Conference </em></font> 
</span>
<br>
<div id="" class="bib" style="display:none;">
	<pre>
	</pre>
</div>

<div id="" class="abstract" style="display:none;">
	<p style="text-align:justify; color:black;font-family:Monaco;"> 
		<font size="3">
		</font>
	</p>
</div>



<!-- Paper 07 -->
ðŸ“Œ <span style="color:blue;font-family:Trebuchet MS;">**Tackling Hallucination in Bengali NLP: Enhancing Paraphrase Generation, Reading Comprehension, and Formal Application Writing Using LLMs with Few-Shot Learning, Fine-Tuning, and RAG**</span><br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Authors</strong>: Saidur Rahman Sujon, Ahmadul Karim Chowdhury, <strong style="color:green">Fatema Tuj Johora Faria</strong>, Mukaffi Bin Moin and Faisal Muhammad Shah</font>
</span>
<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Conference:</strong><em> Submitted to an A* Rank Conference </em></font> 
</span>
<br>
<!-- [<a style="color:red;" href="#" onclick="$('#Tack2024_abstract').toggle();return false;"><font size="3">Abstract</font></a>] [[<span style ="color:red"><font size="3">PDF</font></span>]] [[<span style ="color:red"><font size="3">Code</font></span>]] [[<span style ="color:red"><font size="3">Dataset</font></span>]] [<a style="color:red;" href="#" onclick="$('#Tack2024_bib').toggle();return false;"><font size="3">Citation bib</font></a>]  -->

<div id="" class="bib" style="display:none;">
	<pre>
	</pre>
</div>

<div id="" class="abstract" style="display:none;">
	<p style="text-align:justify; color:black;font-family:Monaco;"> 
		<font size="3">
		</font>
	</p>
</div>












<!-- Paper 06 -->
ðŸ“Œ [<span style="color:blue;font-family:Trebuchet MS;">**Uddessho: An Extensive Benchmark Dataset for Multimodal Author Intent Classification in Low-Resource Bangla Language**</span>](https://arxiv.org/abs/2409.09504)<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Authors</strong>: <strong style="color:green">Fatema Tuj Johora Faria</strong>, Mukaffi Bin Moin, Md. Mahfuzur Rahman, Md Morshed Alam Shanto, Asif Iftekher Fahim and Md. Moinul Hoque</font>
</span>
<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Conference:</strong><em> 18th International Conference on Information Technology and Applications (ICITA 2024) </em></font> ([ICITA 2024](https://icita.world/?__im-rgVYHazg=104405410931315538#/))
</span>
<br>
[<a style="color:red;" href="#" onclick="$('#Uddessho2024_abstract').toggle();return false;"><font size="3">Abstract</font></a>] [[<span style ="color:red"><font size="3">PDF</font></span>](https://arxiv.org/pdf/2409.09504)] [[<span style ="color:red"><font size="3">Code</font></span>](https://github.com/fatemafaria142/Uddessho-An-Benchmark-Dataset-for-Multimodal-Author-Intent-Classification-in-Bangla-Language)] [[<span style ="color:red"><font size="3">Dataset</font></span>](https://data.mendeley.com/datasets/mzxmt8tfjs/1)] [<a style="color:red;" href="#" onclick="$('#Uddessho2024_bib').toggle();return false;"><font size="3">Citation bib</font></a>] 

<div id="Uddessho2024_bib" class="bib" style="display:none;">
	<pre>
	  @misc{faria2024uddesshoextensivebenchmarkdataset,
      		title={Uddessho: An Extensive Benchmark Dataset for Multimodal Author Intent Classification in Low-Resource Bangla Language}, 
      		author={Fatema Tuj Johora Faria and Mukaffi Bin Moin and Md. Mahfuzur Rahman and Md Morshed Alam Shanto and Asif Iftekher Fahim and Md. Moinul Hoque},
      		year={2024},
      		eprint={2409.09504},
      		archivePrefix={arXiv},
      		primaryClass={cs.CL},
      		url={https://arxiv.org/abs/2409.09504}, 
		}
	</pre>
</div>

<div id="Uddessho2024_abstract" class="abstract" style="display:none;">
	<p style="text-align:justify; color:black;font-family:Monaco;"> 
		<font size="3">
			With the increasing popularity of daily information sharing and acquisition on the Internet, this paper introduces an innovative approach for intent classification in Bangla language, focusing on social media posts where individuals share their thoughts and opinions. The proposed method leverages multimodal data with particular emphasis on authorship identification, aiming to understand the underlying purpose behind textual content, especially in the context of varied user-generated posts on social media. Current methods often face challenges in low-resource languages like Bangla, particularly when author traits intricately link with intent, as observed in social media posts. To address this, we present the Multimodal-based Author Bangla Intent Classification (MABIC) framework, utilizing text and images to gain deeper insights into the conveyed intentions. We have created a dataset named "Uddessho," comprising 3,048 instances sourced from social media. Our methodology comprises two approaches for classifying textual intent and multimodal author intent, incorporating early fusion and late fusion techniques. In our experiments, the unimodal approach achieved an accuracy of 64.53% in interpreting Bangla textual intent. In contrast, our multimodal approach significantly outperformed traditional unimodal methods, achieving an accuracy of 76.19%. This represents an improvement of 11.66%. To our best knowledge, this is the first research work on multimodal-based author intent classification for low-resource Bangla language social media posts.
		</font>
	</p>
</div>

<!-- Paper 05 -->
ðŸ“Œ [<span style="color:blue;font-family:Trebuchet MS;">**Motamot: A Dataset for Revealing the Supremacy of Large Language Models over Transformer Models in Bengali Political Sentiment Analysis**</span>](https://arxiv.org/abs/2407.19528)<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Authors</strong>: <strong style="color:green">Fatema Tuj Johora Faria*</strong>, Mukaffi Bin Moin*, Rabeya Islam Mumu, Md Mahabubul Alam Abir, Abrar Nawar Alfy and Mohammad Shafiul Alam</font>
</span>
<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Conference:</strong><em> The IEEE Region 10 Symposium (TENSYMP 2024) </em></font> ([TENSYMP 2024](https://ieeedelhi-tensymp2024.org/))
</span>
<br>
[<a style="color:red;" href="#" onclick="$('#Motamot2024_abstract').toggle();return false;"><font size="3">Abstract</font></a>] [[<span style ="color:red"><font size="3">PDF</font></span>](https://arxiv.org/pdf/2407.19528)] [[<span style ="color:red"><font size="3">Code</font></span>](https://github.com/Mukaffi28/Bengali-Political-Sentiment-Analysis)] [[<span style ="color:red"><font size="3">Dataset</font></span>](https://data.mendeley.com/datasets/hdhnrrwdz2/1)] [<a style="color:red;" href="#" onclick="$('#Motamot2024_bib').toggle();return false;"><font size="3">Citation bib</font></a>] 

<div id="Motamot2024_bib" class="bib" style="display:none;">
	<pre>
	  @misc{faria2024motamotdatasetrevealingsupremacy,
      		title={Motamot: A Dataset for Revealing the Supremacy of Large Language Models over Transformer Models in Bengali Political Sentiment Analysis}, 
      		author={Fatema Tuj Johora Faria and Mukaffi Bin Moin and Rabeya Islam Mumu and Md Mahabubul Alam Abir and Abrar Nawar Alfy and Mohammad Shafiul Alam},
     		year={2024},
      		eprint={2407.19528},
      		archivePrefix={arXiv},
      		primaryClass={cs.CL},
      		url={https://arxiv.org/abs/2407.19528}, 
		}
	</pre>
</div>

<div id="Motamot2024_abstract" class="abstract" style="display:none;">
	<p style="text-align:justify; color:black;font-family:Monaco;"> 
		<font size="3">
			Sentiment analysis is the process of identifying and categorizing people's emotions or opinions regarding various topics. Analyzing political sentiment is critical for understanding the complexities of public opinion processes, especially during election seasons. It gives significant information on voter preferences, attitudes, and current trends. In this study, we investigate political sentiment analysis during Bangladeshi elections, specifically examining how effectively Pre-trained Language Models (PLMs) and Large Language Models (LLMs) capture complex sentiment characteristics. Our study centers on the creation of the "Motamot" dataset, comprising 7,058 instances annotated with positive and negative sentiments, sourced from diverse online newspaper portals, forming a comprehensive resource for political sentiment analysis. We meticulously evaluate the performance of various PLMs including BanglaBERT, Bangla BERT Base, XLM-RoBERTa, mBERT, and sahajBERT, alongside LLMs such as Gemini 1.5 Pro and GPT 3.5 Turbo. Moreover, we explore zero-shot and few-shot learning strategies to enhance our understanding of political sentiment analysis methodologies. Our findings underscore BanglaBERT's commendable accuracy of 88.10% among PLMs. However, the exploration into LLMs reveals even more promising results. Through the adept application of Few-Shot learning techniques, Gemini 1.5 Pro achieves an impressive accuracy of 96.33%, surpassing the remarkable performance of GPT 3.5 Turbo, which stands at 94%. This underscores Gemini 1.5 Pro's status as the superior performer in this comparison.
		</font>
	</p>
</div>

<!-- Paper 04 -->
ðŸ“Œ [<span style="color:blue;font-family:Trebuchet MS;">**PotatoGANs: Utilizing Generative Adversarial Networks, Instance Segmentation, and Explainable AI for Enhanced Potato Disease Identification and Classification**</span>](https://arxiv.org/abs/2405.07332) <br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Authors</strong>: Mohammad Shafiul Alam*, <strong style="color:green">Fatema Tuj Johora Faria*</strong>, Mukaffi Bin Moin*, Ahmed Al Wase, Md. Rabius Sani and Khan Md Hasib</font>
</span>
<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Journal:</strong><em> Pattern Recognition and Image Analysis </em></font> ([Pattern Recognition and Image Analysis](https://link.springer.com/journal/11493))
</span>
<br>
[<a style="color:red;" href="#" onclick="$('#Potato2024_abstract').toggle();return false;"><font size="3">Abstract</font></a>] [[<span style ="color:red"><font size="3">PDF</font></span>](https://arxiv.org/pdf/2405.07332)] [[<span style ="color:red"><font size="3">Code</font></span>](https://github.com/Mukaffi28/ExplainableAI-PotatoGAN-Cutting-Edge-Disease-Identification-for-Potatoes)] [<a style="color:red;" href="#" onclick="$('#Potato2024_bib').toggle();return false;"><font size="3">Citation bib</font></a>] 

<div id="Potato2024_bib" class="bib" style="display:none;">
	<pre>
		@misc{alam2024potatogansutilizinggenerativeadversarial,
      		title={PotatoGANs: Utilizing Generative Adversarial Networks, Instance Segmentation, and Explainable AI for Enhanced Potato Disease Identification and Classification}, 
      		author={Mohammad Shafiul Alam and Fatema Tuj Johora Faria and Mukaffi Bin Moin and Ahmed Al Wase and Md. Rabius Sani and Khan Md Hasib},
      		year={2024},
      		eprint={2405.07332},
      		archivePrefix={arXiv},
      		primaryClass={cs.CV},
      		url={https://arxiv.org/abs/2405.07332}, 
		}
	</pre> 
</div>

<div id="Potato2024_abstract" class="abstract" style="display:none;">
	<p style="text-align:justify; color:black;font-family:Monaco;"> 
		<font size="3">
			Numerous applications have resulted from the automation of agricultural disease segmentation using deep learning techniques. However, when applied to new conditions, these applications frequently face the difficulty of overfitting, resulting in lower segmentation performance. In the context of potato farming, where diseases have a large influence on yields, it is critical for the agricultural economy to quickly and properly identify these diseases. Traditional data augmentation approaches, such as rotation, flip, and translation, have limitations and frequently fail to provide strong generalization results. To address these issues, our research employs a novel approach termed as PotatoGANs. In this novel data augmentation approach, two types of Generative Adversarial Networks (GANs) are utilized to generate synthetic potato disease images from healthy potato images. This approach not only expands the dataset but also adds variety, which helps to enhance model generalization. Using the Inception score as a measure, our experiments show the better quality and realisticness of the images created by PotatoGANs, emphasizing their capacity to resemble real disease images closely. The CycleGAN model outperforms the Pix2Pix GAN model in terms of image quality, as evidenced by its higher IS scores CycleGAN achieves higher Inception scores (IS) of 1.2001 and 1.0900 for black scurf and common scab, respectively. This synthetic data can significantly improve the training of large neural networks. It also reduces data collection costs while enhancing data diversity and generalization capabilities. Our work improves interpretability by combining three gradient-based Explainable AI algorithms (GradCAM, GradCAM++, and ScoreCAM) with three distinct CNN architectures (DenseNet169, Resnet152 V2, InceptionResNet V2) for potato disease classification.
		</font>
	</p>
</div> 


<!-- Paper 03 -->
ðŸ“Œ [<span style="color:blue;font-family:Trebuchet MS;">**Explainable Convolutional Neural Networks for Retinal Fundus Classification and Cutting-Edge Segmentation Models for Retinal Blood Vessels from Fundus Images**</span>](https://arxiv.org/abs/2405.07338) <br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Authors</strong>: <strong style="color:green">Fatema Tuj Johora Faria</strong>, Mukaffi Bin Moin, Pronay Debnath, Asif Iftekher Fahim, Faisal Muhammad Shah</font>
</span>
<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Journal:</strong><em> Under Review in Journal of Visual Communication and Image Representation  </em></font> ([Visual Communication and Image Representation](https://www.sciencedirect.com/journal/journal-of-visual-communication-and-image-representation))
</span>
<br>
[<a style="color:red;" href="#" onclick="$('#Retina2024_abstract').toggle();return false;"><font size="3">Abstract</font></a>] [[<span style ="color:red"><font size="3">PDF</font></span>](https://arxiv.org/pdf/2405.07338)] [[<span style ="color:red"><font size="3">Code</font></span>](https://github.com/fatemafaria142/Retinal-Fundus-Classification-using-XAI-and-Segmentation)]  [<a style="color:red;" href="#" onclick="$('#Retina2024_bib').toggle();return false;"><font size="3">Citation bib</font></a>] 

<div id="Retina2024_bib" class="bib" style="display:none;">
	<pre>
	  @misc{faria2024explainableconvolutionalneuralnetworks,
      		title={Explainable Convolutional Neural Networks for Retinal Fundus Classification and Cutting-Edge Segmentation Models for Retinal Blood Vessels from Fundus Images}, 
      		author={Fatema Tuj Johora Faria and Mukaffi Bin Moin and Pronay Debnath and Asif Iftekher Fahim and Faisal Muhammad Shah},
      		year={2024},
      		eprint={2405.07338},
      		archivePrefix={arXiv},
      		primaryClass={eess.IV},
      		url={https://arxiv.org/abs/2405.07338}, 
		}
	</pre>
</div>

<div id="Retina2024_abstract" class="abstract" style="display:none;">
	<p style="text-align:justify; color:black;font-family:Monaco;"> 
		<font size="3">
			Our research focuses on the critical field of early diagnosis of disease by examining retinal blood vessels in fundus images. While automatic segmentation of retinal blood vessels holds promise for early detection, accurate analysis remains challenging due to the limitations of existing methods, which often lack discrimination power and are susceptible to influences from pathological regions. Our research in fundus image analysis advances deep learning-based classification using eight pre-trained CNN models. To enhance interpretability, we utilize Explainable AI techniques such as Grad-CAM, Grad-CAM++, Score-CAM, Faster Score-CAM, and Layer CAM. These techniques illuminate the decision-making processes of the models, fostering transparency and trust in their predictions. Expanding our exploration, we investigate ten models, including TransUNet with ResNet backbones, Attention U-Net with DenseNet and ResNet backbones, and Swin-UNET. Incorporating diverse architectures such as ResNet50V2, ResNet101V2, ResNet152V2, and DenseNet121 among others, this comprehensive study deepens our insights into attention mechanisms for enhanced fundus image analysis. Among the evaluated models for fundus image classification, ResNet101 emerged with the highest accuracy, achieving an impressive 94.17%. On the other end of the spectrum, EfficientNetB0 exhibited the lowest accuracy among the models, achieving a score of 88.33%. Furthermore, in the domain of fundus image segmentation, Swin-Unet demonstrated a Mean Pixel Accuracy of 86.19%, showcasing its effectiveness in accurately delineating regions of interest within fundus images. Conversely, Attention U-Net with DenseNet201 backbone exhibited the lowest Mean Pixel Accuracy among the evaluated models, achieving a score of 75.87%.
		</font>
	</p>
</div> 




<!-- Paper 02 -->
ðŸ“Œ [<span style="color:blue;font-family:Trebuchet MS;">**Unraveling the Dominance of Large Language Models Over Transformer Models for Bangla Natural Language Inference: A Comprehensive Study**</span>](https://arxiv.org/abs/2405.02937) <br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Authors</strong>: <strong style="color:green">Fatema Tuj Johora Faria,</strong> Mukaffi Bin Moin, Asif Iftekher Fahim, Pronay Debnath, Faisal Muhammad Shah</font>
</span>
<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Conference:</strong><em> 4th International Conference on Computing and Communication Networks (ICCCNet-2024)  </em></font> ([ICCCNet 2024](https://icccn.co.uk/))
</span>
<br>
[<a style="color:red;" href="#" onclick="$('#NLI2023_abstract').toggle();return false;"><font size="3">Abstract</font></a>] [[<span style ="color:red"><font size="3">PDF</font></span>](https://arxiv.org/pdf/2405.02937)] [[<span style ="color:red"><font size="3">Code</font></span>](https://github.com/fatemafaria142/Large-Language-Models-Over-Transformer-Models-for-Bangla-NLI)] [<a style="color:red;" href="#" onclick="$('#NLI2023_bib').toggle();return false;"><font size="3">Citation bib</font></a>] 

<div id="NLI2023_bib" class="bib" style="display:none;">
	<pre>
	  @misc{faria2024unravelingdominancelargelanguage,
      		title={Unraveling the Dominance of Large Language Models Over Transformer Models for Bangla Natural Language Inference: A Comprehensive Study}, 
      		author={Fatema Tuj Johora Faria and Mukaffi Bin Moin and Asif Iftekher Fahim and Pronay Debnath and Faisal Muhammad Shah},
      		year={2024},
      		eprint={2405.02937},
      		archivePrefix={arXiv},
      		primaryClass={cs.CL},
      		url={https://arxiv.org/abs/2405.02937}, 
	  	}
	</pre>
</div>

<div id="NLI2023_abstract" class="abstract" style="display:none;">
	<p style="text-align:justify; color:black;font-family:Monaco;"> 
		<font size="3">
			Natural Language Inference (NLI) is a cornerstone of Natural Language Processing (NLP), providing insights into the entailment relationships between text pairings. It is a critical component of Natural Language Understanding (NLU), demonstrating the ability to extract information from spoken or written interactions. NLI is mainly concerned with determining the entailment relationship between two statements, known as the premise and hypothesis. When the premise logically implies the hypothesis, the pair is labeled "entailment". If the hypothesis contradicts the premise, the pair receives the "contradiction" label. When there is insufficient evidence to establish a connection, the pair is described as "neutral". Despite the success of Large Language Models (LLMs) in various tasks, their effectiveness in NLI remains constrained by issues like low-resource domain accuracy, model overconfidence, and difficulty in capturing human judgment disagreements. This study addresses the underexplored area of evaluating LLMs in low-resourced languages such as Bengali. Through a comprehensive evaluation, we assess the performance of prominent LLMs and state-of-the-art (SOTA) models in Bengali NLP tasks, focusing on natural language inference. Utilizing the XNLI dataset, we conduct zero-shot and few-shot evaluations, comparing LLMs like GPT-3.5 Turbo and Gemini 1.5 Pro with models such as BanglaBERT, Bangla BERT Base, DistilBERT, mBERT, and sahajBERT. Our findings reveal that while LLMs can achieve comparable or superior performance to fine-tuned SOTA models in few-shot scenarios, further research is necessary to enhance our understanding of LLMs in languages with modest resources like Bengali. This study underscores the importance of continued efforts in exploring LLM capabilities across diverse linguistic contexts
		</font>
	</p>
</div> 

<!-- Paper 01 -->
ðŸ“Œ [<span style="color:blue;font-family:Trebuchet MS;">**Exploring Explainable AI Techniques for Improved Interpretability in Lung and Colon Cancer Classification**</span>](https://arxiv.org/abs/2405.04610)<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Authors</strong>: Mukaffi Bin Moin, <strong style="color:green">Fatema Tuj Johora Faria,</strong> Swarnajit Saha, Busra Kamal Rafa, Mohammad Shafiul Alam</font>
</span>
<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Conference:</strong><em> 4th International Conference on Computing and Communication Networks (ICCCNet-2024)  </em></font> ([ICCCNet 2024](https://icccn.co.uk/))
</span>
<br>
[<a style="color:red;" href="#" onclick="$('#lung2023_abstract').toggle();return false;"><font size="3">Abstract</font></a>] [[<span style ="color:red"><font size="3">PDF</font></span>](https://arxiv.org/pdf/2405.04610)] [[<span style ="color:red"><font size="3">Code</font></span>](https://github.com/Mukaffi28/Explainable-AI-for-Lung-and-Colon-Cancer-Classification)][<a style="color:red;" href="#" onclick="$('#lung2023_bib').toggle();return false;"><font size="3">Citation bib</font></a>] 

<div id="lung2023_bib" class="bib" style="display:none;">
	<pre>
	  @misc{moin2024exploringexplainableaitechniques,
      		title={Exploring Explainable AI Techniques for Improved Interpretability in Lung and Colon Cancer Classification}, 
      		author={Mukaffi Bin Moin and Fatema Tuj Johora Faria and Swarnajit Saha and Busra Kamal Rafa and Mohammad Shafiul Alam},
      		year={2024},
      		eprint={2405.04610},
      		archivePrefix={arXiv},
      		primaryClass={eess.IV},
      		url={https://arxiv.org/abs/2405.04610}, 
		}
	</pre>
</div>

<div id="lung2023_abstract" class="abstract" style="display:none;">
	<p style="text-align:justify; color:black;font-family:Monaco;"> 
		<font size="3">
			Lung and colon cancer are serious worldwide health challenges that require early and precise identification to reduce mortality risks. However, diagnosis, which is mostly dependent on histopathologists' competence, presents difficulties and hazards when expertise is insufficient. While diagnostic methods like imaging and blood markers contribute to early detection, histopathology remains the gold standard, although time-consuming and vulnerable to inter-observer mistakes. Limited access to high-end technology further limits patients' ability to receive immediate medical care and diagnosis. Recent advances in deep learning have generated interest in its application to medical imaging analysis, specifically the use of histopathological images to diagnose lung and colon cancer. The goal of this investigation is to use and adapt existing pre-trained CNN-based models, such as Xception, DenseNet201, ResNet101, InceptionV3, DenseNet121, DenseNet169, ResNet152, and InceptionResNetV2, to enhance classification through better augmentation strategies. The results show tremendous progress, with all eight models reaching impressive accuracy ranging from 97% to 99%. Furthermore, attention visualization techniques such as GradCAM, GradCAM++, ScoreCAM, Faster Score-CAM, and LayerCAM, as well as Vanilla Saliency and SmoothGrad, are used to provide insights into the models' classification decisions, thereby improving interpretability and understanding of malignant and benign image classification.
		</font>
	</p>
</div> 

## 2023
---------


<!-- Paper 01 -->
ðŸ“Œ [<span style="color:blue;font-family:Trebuchet MS;">**Vashantor: A Large-scale Multilingual Benchmark Dataset for Automated Translation of Bangla Regional Dialects to Bangla Language**</span>](https://arxiv.org/abs/2311.11142) (<span style="color:red"><strong>Q2</strong></span>)<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Authors</strong>: <strong style="color:green">Fatema Tuj Johora Faria,</strong> Mukaffi Bin Moin, Ahmed Al Wase, Mehidi Ahmmed, Md Rabius Sani, and Tashreef Muhammad.</font>
</span>
<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Journal:</strong><em> Natural Language Processing Journal </em></font> ([Natural Language Processing](https://www.sciencedirect.com/journal/natural-language-processing-journal))
</span>
<br>
[<a style="color:red;" href="#" onclick="$('#vashantor2023_abstract').toggle();return false;"><font size="3">Abstract</font></a>] [[<span style ="color:red"><font size="3">PDF</font></span>](https://arxiv.org/pdf/2311.11142)] [[<span style ="color:red"><font size="3">Code</font></span>](https://github.com/Mukaffi28/Vashantor-A-Large-scale-Multilingual-Benchmark-Dataset)] [[<span style ="color:red"><font size="3">Dataset</font></span>](https://data.mendeley.com/datasets/bj5jgk878b/2)] [<a style="color:red;" href="#" onclick="$('#vashantor2023_bib').toggle();return false;"><font size="3">Citation bib</font></a>] 

<div id="vashantor2023_bib" class="bib" style="display:none;">
	<pre>
	  @misc{faria2023vashantor,
  			title={Vashantor: A Large-scale Multilingual Benchmark Dataset for Automated Translation of Bangla Regional Dialects to Bangla Language},
  			author={Fatema Tuj Johora Faria and Mukaffi Bin Moin and Ahmed Al Wase and Mehidi Ahmmed and Md. Rabius Sani and Tashreef Muhammad},
  			year={2023},
  			eprint={2311.11142},
  			archivePrefix={arXiv},
  			primaryClass={cs.CL}
			}
	</pre>
</div>

<div id="vashantor2023_abstract" class="abstract" style="display:none;">
	<p style="text-align:justify; color:black;font-family:Monaco;"> 
		<font size="3">
			The Bangla linguistic variety is a fascinating mix of regional dialects that adds to the cultural diversity of the Bangla-speaking community. Despite extensive study into translating Bangla to English, English to Bangla, and Banglish to Bangla in the past, there has been a noticeable gap in translating Bangla regional dialects into standard Bangla. In this study, we set out to fill this gap by creating a collection of 32,500 sentences, encompassing Bangla, Banglish, and English, representing five regional Bangla dialects. Our aim is to translate these regional dialects into standard Bangla and detect regions accurately. To achieve this, we proposed models known as mT5 and BanglaT5 for translating regional dialects into standard Bangla. Additionally, we employed mBERT and Bangla-bert-base to determine the specific regions from where these dialects originated. Our experimental results showed the highest BLEU score of 69.06 for Mymensingh regional dialects and the lowest BLEU score of 36.75 for Chittagong regional dialects. We also observed the lowest average word error rate of 0.1548 for Mymensingh regional dialects and the highest of 0.3385 for Chittagong regional dialects. For region detection, we achieved an accuracy of 85.86% for Bangla-bert-base and 84.36% for mBERT. This is the first large-scale investigation of Bangla regional dialects to Bangla machine translation. We believe our findings will not only pave the way for future work on Bangla regional dialects to Bangla machine translation, but will also be useful in solving similar language-related challenges in low-resource language conditions.
		</font>
	</p>
</div> 



<!-- Paper 02 -->
ðŸ“Œ [<span style="color:blue;font-family:Trebuchet MS;">**Classification of Potato Disease with Digital Image Processing Technique: A Hybrid Deep Learning Framework**</span>](https://ieeexplore.ieee.org/document/10099162) (<span style="color:red"></span>)<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Authors</strong>: <strong style="color:green">Fatema Tuj Johora Faria,</strong> Mukaffi Bin Moin, Ahmed Al Wase, Md Rabius Sani, Khan Md Hasib, and Mohammad Shafiul Alam.</font>
</span>
<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Conference:</strong><em> 2023 IEEE 13th Annual Computing and Communication Workshop and Conference (CCWC) </em></font> ([CCWC 2023](https://ieee-ccwc.org/#))
</span>
<br>
[<a style="color:red;" href="#" onclick="$('#potato2023_abstract').toggle();return false;"><font size="3">Abstract</font></a>] [[<span style ="color:red"><font size="3">PDF</font></span>](https://www.researchgate.net/publication/370123763_Classification_of_Potato_Disease_with_Digital_Image_Processing_Technique_A_Hybrid_Deep_Learning_Framework)] [[<span style ="color:red"><font size="3">Code</font></span>](https://github.com/fatemafaria142/Classification-of-Potato-Disease-A-Hybrid-Deep-Learning-Framework)] [[<span style ="color:red"><font size="3">Dataset</font></span>](https://github.com/Mukaffi28/Potato-Disease)] [<a style="color:red;" href="#" onclick="$('#potato2023_bib').toggle();return false;"><font size="3">Citation bib</font></a>] 

<div id="potato2023_bib" class="bib" style="display:none;">
	<pre>
	  @INPROCEEDINGS{10099162,
  		author={Faria, Fatema Tuj Johora and Bin Moin, Mukaffi and Al Wase, Ahmed and Sani, Md. Rabius and Hasib, Khan Md and Alam, Mohammad Shafiul},
  		booktitle={2023 IEEE 13th Annual Computing and Communication Workshop and Conference (CCWC)}, 
  		title={Classification of Potato Disease with Digital Image Processing Technique: A Hybrid Deep Learning Framework}, 
  		year={2023},
  		volume={},
  		number={},
  		pages={0820-0826},
  		keywords={Fungi;Deep learning;Image processing;Digital images;Conferences;Stochastic processes;Training data;Deep learning;Image processing;MobileNet V2;LSTM;GRU;BiLSTM;Disease classification},
  		doi={10.1109/CCWC57344.2023.10099162}}
	</pre>
</div>

<div id="potato2023_abstract" class="abstract" style="display:none;">
	<p style="text-align:justify; color:black;font-family:Monaco;"> 
		<font size="3">
			Potatoes are among the major vegetables in agricultural regions, and it is farmed and utilized all over the world. Potatoes are a high-protein food with several health benefits, but there are numerous diseases associated with potatoes that hamper production. In this research, we developed a hybrid approach that employs image processing and combines MobileNet V2 with LSTM, GRU, and Bidirectional LSTM to evaluate potato disease classes known as Black Scurf, Common Scab, Blackleg, Dry Rot, Pink Rot, Healthy, and Miscellaneous. We examined the outcomes of each architecture after applying it independently to determine the optimal architecture configuration for categorizing potato diseases. In terms of accuracy, the results show that the hybrid MobileNet V2-GRU with Stochastic Gradient Descent optimizer strategy exceeds the other alternative. On the test dataset, we achieved 99% accuracy.
		</font>
	</p>
</div>



