---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

<span style="color:black; font-family:Georgia;">Most recent publication updates can be found on my <a style ="color:#800080;" href="https://scholar.google.com/citations?user=LEken_4AAAAJ&hl=en"><em>[Google Scholar]</em></a> profile.</span><br>
<span style="color:black; font-family:Georgia;">[*] denotes equal contribution</span>

## 2025
--------- 
<!-- Paper 1 -->
ðŸ“Œ [<span style="color:blue;font-family:Trebuchet MS;">**SentimentFormer: A Transformer-Based Multi-Modal Fusion Framework for Enhanced Sentiment Analysis of Memes in Under-Resourced Bangla Language**</span>](https://www.preprints.org/manuscript/202501.1587/v1) (<span style="color:red"><strong>Q2</strong></span>)
<span style="color:black;font-family:Georgia">  
	<font size="3"><strong>Authors</strong>: <strong style="color:green">Fatema Tuj Johora Faria</strong>, Laith H Baniata, Mohammad H Baniata, Mohannad A Khair, Ahmed Ibrahim Bani Ata, Chayut Bunterngchit, and Sangwoo Kang</font>
</span>
<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Journal:</strong><em> Accepted in MDPI Electronics </em></font>  ([Electronics](https://www.mdpi.com/journal/electronics))
</span>
<br>
[<a style="color:red;" href="#" onclick="$('#sentiment2025_abstract').toggle();return false;"><font size="3">Abstract</font></a>] [[<span style ="color:red"><font size="3">PDF</font></span>](https://www.preprints.org/manuscript/202501.1587/v1)] [[<span style ="color:red"><font size="3">Code</font></span>](https://github.com/fatemafaria142/SentimentFormer-A-Transformer-Based-Multi-Modal-Fusion-Framework-for-Sentiment-Analysis-of-Memes)] [[<span style ="color:red"><font size="3">Dataset</font></span>](https://drive.google.com/file/d/12jxFuMz7jtE1kN9fi1ckspgHcKZhkT_B/view)] [<a style="color:red;" href="#" onclick="$('#sentiment2025_bib').toggle();return false;"><font size="3">Citation bib</font></a>] 

<div id="sentiment2025_bib" class="bib" style="display:none;">
	<pre>
	@article{202501.1587,
	doi = {10.20944/preprints202501.1587.v1},
	url = {https://doi.org/10.20944/preprints202501.1587.v1},
	year = 2025,
	month = {January},
	publisher = {Preprints},
	author = {Fatema Tuj Johora Faria and Laith H. Baniata and Mohammad H. Baniata and Mohannad A. Khair and Ahmed Ibrahim Bani Ata and Chayut Bunterngchit and Sangwoo Kang},
	title = {SentimentFormer: A Transformer-Based Multi-Modal Fusion Framework for Enhanced Sentiment Analysis of Memes in Under-Resourced Bangla Language},
	journal = {Preprints}
    }
	</pre>
	
	
</div>

<div id="sentiment2025_abstract" class="abstract" style="display:none;">
	<p style="text-align:justify; color:black;font-family:Monaco;"> 
		<font size="3">
			Social media has increasingly relied on memes as a tool for expressing opinions, making meme sentiment analysis an emerging area of interest for researchers. While much of the research has focused on English-language memes, under-Resource languages, such as Bengali, have received limited attention. Given the surge in social media use, the need for sentiment analysis of memes in these languages has become critical. One of the primary challenges in this field is the lack of benchmark datasets, particularly in languages with fewer resources. To address this, we used the MemoSen dataset, designed for Bengali, which consists of 4,368 memes annotated with three sentiment labels: positive, negative, and neutral. MemoSen is divided into training (70%), test (20%), and validation (10%) sets, with an imbalanced class distribution: 1,349 memes in the positive class, 2,728 in the negative class, and 291 in the neutral class. Our approach leverages advanced deep learning techniques for multimodal sentiment analysis in Bengali, introducing three hybrid approaches. SentimentTextFormer is a text-based, fine-tuned model that utilizes state-of-the-art transformer architectures to accurately extract sentiment-related insights from Bengali text, capturing nuanced linguistic features. SentimentImageFormer is an image-based model that employs cutting-edge transformer-based techniques for precise sentiment classification through visual data. Lastly, SentimentFormer is a hybrid model that seamlessly integrates both text and image modalities using fusion strategies. Early Fusion combines textual and visual features at the input level, enabling the model to jointly learn from both modalities. Late Fusion merges the outputs of separate text and image models, preserving their individual strengths for the final prediction. Intermediate Fusion integrates textual and visual features at intermediate layers, refining their interactions during processing. These fusion strategies combine the strengths of both textual and visual data, enhancing sentiment analysis by exploiting complementary information from multiple sources. The performance of our models was evaluated using various accuracy metrics, with SentimentTextFormer achieving 73.31% accuracy and SentimentImageFormer attaining 64.72%. The hybrid model, SentimentFormer (SwiftFormer with mBERT), employing Intermediate Fusion, shows a notable improvement in accuracy, achieving 79.04%, outperforming SentimentTextFormer by 5.73% and SentimentImageFormer by 14.32%. Among the fusion strategies, SentimentFormer (SwiftFormer with mBERT) achieved the highest accuracy of 79.04%, highlighting the effectiveness of our fusion technique and the reliability of our multimodal framework in improving sentiment analysis accuracy across diverse modalities.
		</font>
	</p>
</div>



## 2024
--------- 

<!-- Paper 1 -->
ðŸ“Œ [<span style="color:blue;font-family:Trebuchet MS;">**Investigating the Predominance of Large Language Models in Low-Resource Bangla Language Over Transformer Models for Hate Speech Detection: A Comparative Analysis**</span>](https://www.mdpi.com/2227-7390/12/23/3687) (<span style="color:red"><strong>Q1</strong></span>)
<span style="color:black;font-family:Georgia">  
	<font size="3"><strong>Authors</strong>: <strong style="color:green">Fatema Tuj Johora Faria</strong>, Laith H. Baniata, and Sangwoo Kang</font>
</span>
<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Journal:</strong><em> Published in MDPI Mathematics </em></font>  ([Mathematics](https://www.mdpi.com/journal/mathematics))
</span>
<br>
[<a style="color:red;" href="#" onclick="$('#hate2024_abstract').toggle();return false;"><font size="3">Abstract</font></a>] [[<span style ="color:red"><font size="3">PDF</font></span>](https://www.mdpi.com/2227-7390/12/23/3687)] [[<span style ="color:red"><font size="3">Code</font></span>](https://github.com/fatemafaria142/Bangla-Hate-Speech-Detection)] [[<span style ="color:red"><font size="3">Dataset</font></span>](https://www.kaggle.com/datasets/naurosromim/bdshs)] [<a style="color:red;" href="#" onclick="$('#Hate2024_bib').toggle();return false;"><font size="3">Citation bib</font></a>] 

<div id="Hate2024_bib" class="bib" style="display:none;">
	<pre>
	@Article{math12233687,
	AUTHOR = {Faria, Fatema Tuj Johora and Baniata, Laith H. and Kang, Sangwoo},
	TITLE = {Investigating the Predominance of Large Language Models in Low-Resource Bangla Language over Transformer Models for Hate Speech Detection: A Comparative Analysis},
	JOURNAL = {Mathematics},
	VOLUME = {12},
	YEAR = {2024},
	NUMBER = {23},
	ARTICLE-NUMBER = {3687},
	URL = {https://www.mdpi.com/2227-7390/12/23/3687},
	ISSN = {2227-7390},
	DOI = {10.3390/math12233687}
	}
	</pre>
	
	
</div>

<div id="hate2024_abstract" class="abstract" style="display:none;">
	<p style="text-align:justify; color:black;font-family:Monaco;"> 
		<font size="3">
			The rise in abusive language on social media is a significant threat to mental health and social cohesion. For Bengali speakers, the need for effective detection is critical. However, current methods fall short in addressing the massive volume of content. Improved techniques are urgently needed to combat online hate speech in Bengali. Traditional machine learning techniques, while useful, often require large, linguistically diverse datasets to train models effectively. This paper addresses the urgent need for improved hate speech detection methods in Bengali, aiming to fill the existing research gap. Contextual understanding is crucial in differentiating between harmful speech and benign expressions. Large language models (LLMs) have shown state-of-the-art performance in various natural language tasks due to their extensive training on vast amounts of data. We explore the application of LLMs, specifically GPT-3.5 Turbo and Gemini 1.5 Pro, for Bengali hate speech detection using Zero-Shot and Few-Shot Learning approaches. Unlike conventional methods, Zero-Shot Learning identifies hate speech without task-specific training data, making it highly adaptable to new datasets and languages. Few-Shot Learning, on the other hand, requires minimal labeled examples, allowing for efficient model training with limited resources. Our experimental results show that LLMs outperform traditional approaches. In this study, we evaluate GPT-3.5 Turbo and Gemini 1.5 Pro on multiple datasets. To further enhance our study, we consider the distribution of comments in different datasets and the challenge of class imbalance, which can affect model performance. The BD-SHS dataset consists of 35,197 comments in the training set, 7542 in the validation set, and 7542 in the test set. The Bengali Hate Speech Dataset v1.0 and v2.0 include comments distributed across various hate categories: personal hate (629), political hate (1771), religious hate (502), geopolitical hate (1179), and gender abusive hate (316). The Bengali Hate Dataset comprises 7500 non-hate and 7500 hate comments. GPT-3.5 Turbo achieved impressive results with 97.33%, 98.42%, and 98.53% accuracy. In contrast, Gemini 1.5 Pro showed lower performance across all datasets. Specifically, GPT-3.5 Turbo excelled with significantly higher accuracy compared to Gemini 1.5 Pro. These outcomes highlight a 6.28% increase in accuracy compared to traditional methods, which achieved 92.25%. Our research contributes to the growing body of literature on LLM applications in natural language processing, particularly in the context of low-resource languages.

		</font>
	</p>
</div>





<!-- Paper 02 -->
ðŸ“Œ [<span style="color:blue;font-family:Trebuchet MS;">**Motamot: A Dataset for Revealing the Supremacy of Large Language Models over Transformer Models in Bengali Political Sentiment Analysis**</span>](https://ieeexplore.ieee.org/document/10752197)<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Authors</strong>: <strong style="color:green">Fatema Tuj Johora Faria*</strong>, Mukaffi Bin Moin*, Rabeya Islam Mumu, Md Mahabubul Alam Abir, Abrar Nawar Alfy and Mohammad Shafiul Alam</font>
</span>
<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Conference:</strong><em> The IEEE Region 10 Symposium (TENSYMP 2024) </em></font> ([TENSYMP 2024](https://ieeedelhi-tensymp2024.org/))
</span>
<br>
[<a style="color:red;" href="#" onclick="$('#Motamot2024_abstract').toggle();return false;"><font size="3">Abstract</font></a>] [[<span style ="color:red"><font size="3">PDF</font></span>](https://arxiv.org/pdf/2407.19528)] [[<span style ="color:red"><font size="3">Code</font></span>](https://github.com/Mukaffi28/Bengali-Political-Sentiment-Analysis)] [[<span style ="color:red"><font size="3">Dataset</font></span>](https://data.mendeley.com/datasets/hdhnrrwdz2/1)] [<a style="color:red;" href="#" onclick="$('#Motamot2024_bib').toggle();return false;"><font size="3">Citation bib</font></a>] 

<div id="Motamot2024_bib" class="bib" style="display:none;">
	<pre>
	@INPROCEEDINGS{10752197,
      	author={Johora Faria, Fatema Tuj and Moin, Mukaffi Bin and Mumu, Rabeya Islam and Alam Abir, Md Mahabubul and Alfy, Abrar Nawar and Alam, Mohammad Shafiul},
      	booktitle={2024 IEEE Region 10 Symposium (TENSYMP)}, 
      	title={Motamot: A Dataset for Revealing the Supremacy of Large Language Models Over Transformer Models in Bengali Political Sentiment Analysis}, 
      	year={2024},
      	volume={},
      	number={},
      	pages={1-8},
      	keywords={Sentiment analysis;Analytical models;Accuracy;Voting;Large language models;Transformers;Market research;Few shot learning;Portals;IEEE Regions;Political Sentiment Analysis;Pre-trained Language Models;Large Language Models;Gem-ini 1.5 Pro;GPT 3.5 Turbo;Zero-shot Learning;Fewshot Learning;Low-resource Language},
      	doi={10.1109/TENSYMP61132.2024.10752197}
		}
   </pre>
</div>

<div id="Motamot2024_abstract" class="abstract" style="display:none;">
	<p style="text-align:justify; color:black;font-family:Monaco;"> 
		<font size="3">
			Sentiment analysis is the process of identifying and categorizing people's emotions or opinions regarding various topics. Analyzing political sentiment is critical for understanding the complexities of public opinion processes, especially during election seasons. It gives significant information on voter preferences, attitudes, and current trends. In this study, we investigate political sentiment analysis during Bangladeshi elections, specifically examining how effectively Pre-trained Language Models (PLMs) and Large Language Models (LLMs) capture complex sentiment characteristics. Our study centers on the creation of the "Motamot" dataset, comprising 7,058 instances annotated with positive and negative sentiments, sourced from diverse online newspaper portals, forming a comprehensive resource for political sentiment analysis. We meticulously evaluate the performance of various PLMs including BanglaBERT, Bangla BERT Base, XLM-RoBERTa, mBERT, and sahajBERT, alongside LLMs such as Gemini 1.5 Pro and GPT 3.5 Turbo. Moreover, we explore zero-shot and few-shot learning strategies to enhance our understanding of political sentiment analysis methodologies. Our findings underscore BanglaBERT's commendable accuracy of 88.10% among PLMs. However, the exploration into LLMs reveals even more promising results. Through the adept application of Few-Shot learning techniques, Gemini 1.5 Pro achieves an impressive accuracy of 96.33%, surpassing the remarkable performance of GPT 3.5 Turbo, which stands at 94%. This underscores Gemini 1.5 Pro's status as the superior performer in this comparison.
		</font>
	</p>
</div>



<!-- Paper 3 -->
ðŸ“Œ <span style="color:blue;font-family:Trebuchet MS;">**MultiBanFakeDetect: Integrating Advanced Fusion Techniques for Multimodal Detection of Bangla Fake News in Under-Resourced Contexts** </span> (<span style="color:red"><strong>Q1</strong></span>)<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Authors</strong>: <strong style="color:green">Fatema Tuj Johora Faria</strong>, Mukaffi Bin Moin, Zayeed Hasan, Md Arafat Alam Khandaker, Niful Islam, Khan Md Hasib, and M. F. Mridha</font>
</span>
<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Journal:</strong><em> Under Review in International Journal of Information Management Data Insights </em></font>  ([International Journal of Information Management Data Insights](https://www.sciencedirect.com/journal/international-journal-of-information-management-data-insights))
</span>
<br>
[[<span style ="color:red"><font size="3">Code</font></span>](https://github.com/fatemafaria142/MultiBanFakeDetect-An-Extensive-Benchmark-Dataset-for-Multimodal-Bangla-Fake-News-Detection)] [[<span style ="color:red"><font size="3">Dataset</font></span>](https://data.mendeley.com/datasets/k5pbz9795f/1)]



<!-- Paper 4 -->
ðŸ“Œ <span style="color:blue;font-family:Trebuchet MS;">**BanglaCalamityMMD: A Comprehensive Benchmark Dataset for Multimodal Disaster Identification in the Low-Resource Bangla Language** </span>  (<span style="color:red"><strong>Q1</strong></span>)<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Authors</strong>: <strong style="color:green">Fatema Tuj Johora Faria</strong>, Mukaffi Bin Moin, Busra Kamal Rafa, Swarnajit Saha, Md. Mahfuzur Rahman, Khan Md Hasib, and M. F. Mridha</font>
</span>
<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Journal:</strong><em> Under Review in International Journal of Disaster Risk Reduction </em></font>  ([Disaster Risk Reduction](https://www.sciencedirect.com/journal/international-journal-of-disaster-risk-reduction))
</span>
<br>
[[<span style ="color:red"><font size="3">Code</font></span>](https://github.com/Mukaffi28/BanglaCalamityMMD-A-Comprehensive-Benchmark-Dataset-for-Multimodal-Disaster-Identification)] [[<span style ="color:red"><font size="3">Dataset</font></span>](https://data.mendeley.com/datasets/7dggbjn5sd/1)] 

<div id="" class="bib" style="display:none;">
	<pre>
	</pre>
</div>

<div id="" class="abstract" style="display:none;">
	<p style="text-align:justify; color:black;font-family:Monaco;"> 
		<font size="3">
		</font>
	</p>
</div>


<!-- Paper 5 -->
ðŸ“Œ <span style="color:blue;font-family:Trebuchet MS;">**BanglaMemeEvidence: A Multimodal Benchmark Dataset for Explanatory Evidence Detection in Bengali MemesBanglaMemeEvidence: A Multimodal Benchmark Dataset for Explanatory Evidence Detection in Bengali Memes**</span><br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Authors</strong>: <strong style="color:green">Fatema Tuj Johora Faria</strong>, Mukaffi Bin Moin, Asif Iftekher Fahim, Pronay Debnath, and Faisal Muhammad Shah.</font>
</span>
<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Conference:</strong><em> Submitted to an A* Rank Conference </em></font> 
</span>
<br>
<div id="" class="bib" style="display:none;">
	<pre>
	</pre>
</div>

<div id="" class="abstract" style="display:none;">
	<p style="text-align:justify; color:black;font-family:Monaco;"> 
		<font size="3">
		</font>
	</p>
</div>



<!-- Paper 6 -->
ðŸ“Œ <span style="color:blue;font-family:Trebuchet MS;">**Enhancing Bangla NLP Tasks with LLMs: A Study on Few-Shot Learning, RAG, and Fine-Tuning Techniques**</span><br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Authors</strong>: Saidur Rahman Sujon, Ahmadul Karim Chowdhury, <strong style="color:green">Fatema Tuj Johora Faria</strong>, Mukaffi Bin Moin and Faisal Muhammad Shah</font>
</span>
<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Conference:</strong><em> Submitted to an A* Rank Conference </em></font> 
</span>
<br>


<div id="" class="bib" style="display:none;">
	<pre>
	</pre>
</div>

<div id="" class="abstract" style="display:none;">
	<p style="text-align:justify; color:black;font-family:Monaco;"> 
		<font size="3">
		</font>
	</p>
</div>












<!-- Paper 7 -->
ðŸ“Œ [<span style="color:blue;font-family:Trebuchet MS;">**Uddessho: An Extensive Benchmark Dataset for Multimodal Author Intent Classification in Low-Resource Bangla Language**</span>](https://arxiv.org/abs/2409.09504)<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Authors</strong>: <strong style="color:green">Fatema Tuj Johora Faria</strong>, Mukaffi Bin Moin, Md. Mahfuzur Rahman, Md Morshed Alam Shanto, Asif Iftekher Fahim and Md. Moinul Hoque</font>
</span>
<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Conference:</strong><em> 18th International Conference on Information Technology and Applications (ICITA 2024) </em></font> ([ICITA 2024](https://icita.world/?__im-rgVYHazg=104405410931315538#/))
</span>
<br>
[<a style="color:red;" href="#" onclick="$('#Uddessho2024_abstract').toggle();return false;"><font size="3">Abstract</font></a>] [[<span style ="color:red"><font size="3">PDF</font></span>](https://arxiv.org/pdf/2409.09504)] [[<span style ="color:red"><font size="3">Code</font></span>](https://github.com/fatemafaria142/Uddessho-An-Benchmark-Dataset-for-Multimodal-Author-Intent-Classification-in-Bangla-Language)] [[<span style ="color:red"><font size="3">Dataset</font></span>](https://data.mendeley.com/datasets/mzxmt8tfjs/1)] [<a style="color:red;" href="#" onclick="$('#Uddessho2024_bib').toggle();return false;"><font size="3">Citation bib</font></a>] 

<div id="Uddessho2024_bib" class="bib" style="display:none;">
	<pre>
	  @misc{faria2024uddesshoextensivebenchmarkdataset,
      		title={Uddessho: An Extensive Benchmark Dataset for Multimodal Author Intent Classification in Low-Resource Bangla Language}, 
      		author={Fatema Tuj Johora Faria and Mukaffi Bin Moin and Md. Mahfuzur Rahman and Md Morshed Alam Shanto and Asif Iftekher Fahim and Md. Moinul Hoque},
      		year={2024},
      		eprint={2409.09504},
      		archivePrefix={arXiv},
      		primaryClass={cs.CL},
      		url={https://arxiv.org/abs/2409.09504}, 
		}
	</pre>
</div>

<div id="Uddessho2024_abstract" class="abstract" style="display:none;">
	<p style="text-align:justify; color:black;font-family:Monaco;"> 
		<font size="3">
			With the increasing popularity of daily information sharing and acquisition on the Internet, this paper introduces an innovative approach for intent classification in Bangla language, focusing on social media posts where individuals share their thoughts and opinions. The proposed method leverages multimodal data with particular emphasis on authorship identification, aiming to understand the underlying purpose behind textual content, especially in the context of varied user-generated posts on social media. Current methods often face challenges in low-resource languages like Bangla, particularly when author traits intricately link with intent, as observed in social media posts. To address this, we present the Multimodal-based Author Bangla Intent Classification (MABIC) framework, utilizing text and images to gain deeper insights into the conveyed intentions. We have created a dataset named "Uddessho," comprising 3,048 instances sourced from social media. Our methodology comprises two approaches for classifying textual intent and multimodal author intent, incorporating early fusion and late fusion techniques. In our experiments, the unimodal approach achieved an accuracy of 64.53% in interpreting Bangla textual intent. In contrast, our multimodal approach significantly outperformed traditional unimodal methods, achieving an accuracy of 76.19%. This represents an improvement of 11.66%. To our best knowledge, this is the first research work on multimodal-based author intent classification for low-resource Bangla language social media posts.
		</font>
	</p>
</div>




<!-- Paper 8 -->
ðŸ“Œ [<span style="color:blue;font-family:Trebuchet MS;">**PotatoGANs: Utilizing Generative Adversarial Networks, Instance Segmentation, and Explainable AI for Enhanced Potato Disease Identification and Classification**</span>](https://arxiv.org/abs/2405.07332) (<span style="color:red"><strong>Q2</strong></span>)<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Authors</strong>: Mohammad Shafiul Alam*, <strong style="color:green">Fatema Tuj Johora Faria*</strong>, Mukaffi Bin Moin*, Ahmed Al Wase, Md. Rabius Sani and Khan Md Hasib</font>
</span>
<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Journal:</strong><em> Under Review in Journal of Intelligent Information Systems </em></font> ([Journal of Intelligent Information Systems](https://link.springer.com/journal/10844))
</span>
<br>
[<a style="color:red;" href="#" onclick="$('#Potato2024_abstract').toggle();return false;"><font size="3">Abstract</font></a>] [[<span style ="color:red"><font size="3">PDF</font></span>](https://arxiv.org/pdf/2405.07332)] [[<span style ="color:red"><font size="3">Code</font></span>](https://github.com/Mukaffi28/ExplainableAI-PotatoGAN-Cutting-Edge-Disease-Identification-for-Potatoes)] [<a style="color:red;" href="#" onclick="$('#Potato2024_bib').toggle();return false;"><font size="3">Citation bib</font></a>] 

<div id="Potato2024_bib" class="bib" style="display:none;">
	<pre>
		@misc{alam2024potatogansutilizinggenerativeadversarial,
      		title={PotatoGANs: Utilizing Generative Adversarial Networks, Instance Segmentation, and Explainable AI for Enhanced Potato Disease Identification and Classification}, 
      		author={Mohammad Shafiul Alam and Fatema Tuj Johora Faria and Mukaffi Bin Moin and Ahmed Al Wase and Md. Rabius Sani and Khan Md Hasib},
      		year={2024},
      		eprint={2405.07332},
      		archivePrefix={arXiv},
      		primaryClass={cs.CV},
      		url={https://arxiv.org/abs/2405.07332}, 
		}
	</pre> 
</div>

<div id="Potato2024_abstract" class="abstract" style="display:none;">
	<p style="text-align:justify; color:black;font-family:Monaco;"> 
		<font size="3">
			Numerous applications have resulted from the automation of agricultural disease segmentation using deep learning techniques. However, when applied to new conditions, these applications frequently face the difficulty of overfitting, resulting in lower segmentation performance. In the context of potato farming, where diseases have a large influence on yields, it is critical for the agricultural economy to quickly and properly identify these diseases. Traditional data augmentation approaches, such as rotation, flip, and translation, have limitations and frequently fail to provide strong generalization results. To address these issues, our research employs a novel approach termed as PotatoGANs. In this novel data augmentation approach, two types of Generative Adversarial Networks (GANs) are utilized to generate synthetic potato disease images from healthy potato images. This approach not only expands the dataset but also adds variety, which helps to enhance model generalization. Using the Inception score as a measure, our experiments show the better quality and realisticness of the images created by PotatoGANs, emphasizing their capacity to resemble real disease images closely. The CycleGAN model outperforms the Pix2Pix GAN model in terms of image quality, as evidenced by its higher IS scores CycleGAN achieves higher Inception scores (IS) of 1.2001 and 1.0900 for black scurf and common scab, respectively. This synthetic data can significantly improve the training of large neural networks. It also reduces data collection costs while enhancing data diversity and generalization capabilities. Our work improves interpretability by combining three gradient-based Explainable AI algorithms (GradCAM, GradCAM++, and ScoreCAM) with three distinct CNN architectures (DenseNet169, Resnet152 V2, InceptionResNet V2) for potato disease classification.
		</font>
	</p>
</div> 


<!-- Paper 9 -->
ðŸ“Œ [<span style="color:blue;font-family:Trebuchet MS;">**Explainable Convolutional Neural Networks for Retinal Fundus Classification and Cutting-Edge Segmentation Models for Retinal Blood Vessels from Fundus Images**</span>](https://arxiv.org/abs/2405.07338) (<span style="color:red"><strong>Q1</strong></span>)<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Authors</strong>: <strong style="color:green">Fatema Tuj Johora Faria</strong>, Mukaffi Bin Moin, Pronay Debnath, Asif Iftekher Fahim, Faisal Muhammad Shah</font>
</span>
<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Journal:</strong><em> Under Review in Journal of Visual Communication and Image Representation  </em></font> ([Journal of Visual Communication and Image Representation](https://www.sciencedirect.com/journal/journal-of-visual-communication-and-image-representation))
</span>
<br>
[<a style="color:red;" href="#" onclick="$('#Retina2024_abstract').toggle();return false;"><font size="3">Abstract</font></a>] [[<span style ="color:red"><font size="3">PDF</font></span>](https://arxiv.org/pdf/2405.07338)] [[<span style ="color:red"><font size="3">Code</font></span>](https://github.com/fatemafaria142/Retinal-Fundus-Classification-using-XAI-and-Segmentation)]  [<a style="color:red;" href="#" onclick="$('#Retina2024_bib').toggle();return false;"><font size="3">Citation bib</font></a>] 

<div id="Retina2024_bib" class="bib" style="display:none;">
	<pre>
	  @misc{faria2024explainableconvolutionalneuralnetworks,
      		title={Explainable Convolutional Neural Networks for Retinal Fundus Classification and Cutting-Edge Segmentation Models for Retinal Blood Vessels from Fundus Images}, 
      		author={Fatema Tuj Johora Faria and Mukaffi Bin Moin and Pronay Debnath and Asif Iftekher Fahim and Faisal Muhammad Shah},
      		year={2024},
      		eprint={2405.07338},
      		archivePrefix={arXiv},
      		primaryClass={eess.IV},
      		url={https://arxiv.org/abs/2405.07338}, 
		}
	</pre>
</div>

<div id="Retina2024_abstract" class="abstract" style="display:none;">
	<p style="text-align:justify; color:black;font-family:Monaco;"> 
		<font size="3">
			Our research focuses on the critical field of early diagnosis of disease by examining retinal blood vessels in fundus images. While automatic segmentation of retinal blood vessels holds promise for early detection, accurate analysis remains challenging due to the limitations of existing methods, which often lack discrimination power and are susceptible to influences from pathological regions. Our research in fundus image analysis advances deep learning-based classification using eight pre-trained CNN models. To enhance interpretability, we utilize Explainable AI techniques such as Grad-CAM, Grad-CAM++, Score-CAM, Faster Score-CAM, and Layer CAM. These techniques illuminate the decision-making processes of the models, fostering transparency and trust in their predictions. Expanding our exploration, we investigate ten models, including TransUNet with ResNet backbones, Attention U-Net with DenseNet and ResNet backbones, and Swin-UNET. Incorporating diverse architectures such as ResNet50V2, ResNet101V2, ResNet152V2, and DenseNet121 among others, this comprehensive study deepens our insights into attention mechanisms for enhanced fundus image analysis. Among the evaluated models for fundus image classification, ResNet101 emerged with the highest accuracy, achieving an impressive 94.17%. On the other end of the spectrum, EfficientNetB0 exhibited the lowest accuracy among the models, achieving a score of 88.33%. Furthermore, in the domain of fundus image segmentation, Swin-Unet demonstrated a Mean Pixel Accuracy of 86.19%, showcasing its effectiveness in accurately delineating regions of interest within fundus images. Conversely, Attention U-Net with DenseNet201 backbone exhibited the lowest Mean Pixel Accuracy among the evaluated models, achieving a score of 75.87%.
		</font>
	</p>
</div> 




<!-- Paper 10 -->
ðŸ“Œ [<span style="color:blue;font-family:Trebuchet MS;">**Unraveling the Dominance of Large Language Models Over Transformer Models for Bangla Natural Language Inference: A Comprehensive Study**</span>](https://arxiv.org/abs/2405.02937) <br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Authors</strong>: <strong style="color:green">Fatema Tuj Johora Faria,</strong> Mukaffi Bin Moin, Asif Iftekher Fahim, Pronay Debnath, Faisal Muhammad Shah</font>
</span>
<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Conference:</strong><em> 4th International Conference on Computing and Communication Networks (ICCCNet-2024)  </em></font> ([ICCCNet 2024](https://icccn.co.uk/))
</span>
<br>
[<a style="color:red;" href="#" onclick="$('#NLI2023_abstract').toggle();return false;"><font size="3">Abstract</font></a>] [[<span style ="color:red"><font size="3">PDF</font></span>](https://arxiv.org/pdf/2405.02937)] [[<span style ="color:red"><font size="3">Code</font></span>](https://github.com/fatemafaria142/Large-Language-Models-Over-Transformer-Models-for-Bangla-NLI)] [<a style="color:red;" href="#" onclick="$('#NLI2023_bib').toggle();return false;"><font size="3">Citation bib</font></a>] 

<div id="NLI2023_bib" class="bib" style="display:none;">
	<pre>
	  @misc{faria2024unravelingdominancelargelanguage,
      		title={Unraveling the Dominance of Large Language Models Over Transformer Models for Bangla Natural Language Inference: A Comprehensive Study}, 
      		author={Fatema Tuj Johora Faria and Mukaffi Bin Moin and Asif Iftekher Fahim and Pronay Debnath and Faisal Muhammad Shah},
      		year={2024},
      		eprint={2405.02937},
      		archivePrefix={arXiv},
      		primaryClass={cs.CL},
      		url={https://arxiv.org/abs/2405.02937}, 
	  	}
	</pre>
</div>

<div id="NLI2023_abstract" class="abstract" style="display:none;">
	<p style="text-align:justify; color:black;font-family:Monaco;"> 
		<font size="3">
			Natural Language Inference (NLI) is a cornerstone of Natural Language Processing (NLP), providing insights into the entailment relationships between text pairings. It is a critical component of Natural Language Understanding (NLU), demonstrating the ability to extract information from spoken or written interactions. NLI is mainly concerned with determining the entailment relationship between two statements, known as the premise and hypothesis. When the premise logically implies the hypothesis, the pair is labeled "entailment". If the hypothesis contradicts the premise, the pair receives the "contradiction" label. When there is insufficient evidence to establish a connection, the pair is described as "neutral". Despite the success of Large Language Models (LLMs) in various tasks, their effectiveness in NLI remains constrained by issues like low-resource domain accuracy, model overconfidence, and difficulty in capturing human judgment disagreements. This study addresses the underexplored area of evaluating LLMs in low-resourced languages such as Bengali. Through a comprehensive evaluation, we assess the performance of prominent LLMs and state-of-the-art (SOTA) models in Bengali NLP tasks, focusing on natural language inference. Utilizing the XNLI dataset, we conduct zero-shot and few-shot evaluations, comparing LLMs like GPT-3.5 Turbo and Gemini 1.5 Pro with models such as BanglaBERT, Bangla BERT Base, DistilBERT, mBERT, and sahajBERT. Our findings reveal that while LLMs can achieve comparable or superior performance to fine-tuned SOTA models in few-shot scenarios, further research is necessary to enhance our understanding of LLMs in languages with modest resources like Bengali. This study underscores the importance of continued efforts in exploring LLM capabilities across diverse linguistic contexts
		</font>
	</p>
</div> 

<!-- Paper 11 -->
ðŸ“Œ [<span style="color:blue;font-family:Trebuchet MS;">**Exploring Explainable AI Techniques for Improved Interpretability in Lung and Colon Cancer Classification**</span>](https://arxiv.org/abs/2405.04610)<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Authors</strong>: Mukaffi Bin Moin, <strong style="color:green">Fatema Tuj Johora Faria,</strong> Swarnajit Saha, Busra Kamal Rafa, Mohammad Shafiul Alam</font>
</span>
<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Conference:</strong><em> 4th International Conference on Computing and Communication Networks (ICCCNet-2024)  </em></font> ([ICCCNet 2024](https://icccn.co.uk/))
</span>
<br>
[<a style="color:red;" href="#" onclick="$('#lung2023_abstract').toggle();return false;"><font size="3">Abstract</font></a>] [[<span style ="color:red"><font size="3">PDF</font></span>](https://arxiv.org/pdf/2405.04610)] [[<span style ="color:red"><font size="3">Code</font></span>](https://github.com/Mukaffi28/Explainable-AI-for-Lung-and-Colon-Cancer-Classification)][<a style="color:red;" href="#" onclick="$('#lung2023_bib').toggle();return false;"><font size="3">Citation bib</font></a>] 

<div id="lung2023_bib" class="bib" style="display:none;">
	<pre>
	  @misc{moin2024exploringexplainableaitechniques,
      		title={Exploring Explainable AI Techniques for Improved Interpretability in Lung and Colon Cancer Classification}, 
      		author={Mukaffi Bin Moin and Fatema Tuj Johora Faria and Swarnajit Saha and Busra Kamal Rafa and Mohammad Shafiul Alam},
      		year={2024},
      		eprint={2405.04610},
      		archivePrefix={arXiv},
      		primaryClass={eess.IV},
      		url={https://arxiv.org/abs/2405.04610}, 
		}
	</pre>
</div>

<div id="lung2023_abstract" class="abstract" style="display:none;">
	<p style="text-align:justify; color:black;font-family:Monaco;"> 
		<font size="3">
			Lung and colon cancer are serious worldwide health challenges that require early and precise identification to reduce mortality risks. However, diagnosis, which is mostly dependent on histopathologists' competence, presents difficulties and hazards when expertise is insufficient. While diagnostic methods like imaging and blood markers contribute to early detection, histopathology remains the gold standard, although time-consuming and vulnerable to inter-observer mistakes. Limited access to high-end technology further limits patients' ability to receive immediate medical care and diagnosis. Recent advances in deep learning have generated interest in its application to medical imaging analysis, specifically the use of histopathological images to diagnose lung and colon cancer. The goal of this investigation is to use and adapt existing pre-trained CNN-based models, such as Xception, DenseNet201, ResNet101, InceptionV3, DenseNet121, DenseNet169, ResNet152, and InceptionResNetV2, to enhance classification through better augmentation strategies. The results show tremendous progress, with all eight models reaching impressive accuracy ranging from 97% to 99%. Furthermore, attention visualization techniques such as GradCAM, GradCAM++, ScoreCAM, Faster Score-CAM, and LayerCAM, as well as Vanilla Saliency and SmoothGrad, are used to provide insights into the models' classification decisions, thereby improving interpretability and understanding of malignant and benign image classification.
		</font>
	</p>
</div> 

## 2023
---------


<!-- Paper 12 -->
ðŸ“Œ [<span style="color:blue;font-family:Trebuchet MS;">**Vashantor: A Large-scale Multilingual Benchmark Dataset for Automated Translation of Bangla Regional Dialects to Bangla Language**</span>](https://arxiv.org/abs/2311.11142) (<span style="color:red"><strong>Q1</strong></span>)<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Authors</strong>: <strong style="color:green">Fatema Tuj Johora Faria,</strong> Mukaffi Bin Moin, Ahmed Al Wase, Mehidi Ahmmed, Md Rabius Sani, and Tashreef Muhammad.</font>
</span>
<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Journal:</strong><em> Under Review in Neural Computing and Applications </em></font> ([Neural Computing and Applications](https://link.springer.com/journal/521))
</span>
<br>
[<a style="color:red;" href="#" onclick="$('#vashantor2023_abstract').toggle();return false;"><font size="3">Abstract</font></a>] [[<span style ="color:red"><font size="3">PDF</font></span>](https://arxiv.org/pdf/2311.11142)] [[<span style ="color:red"><font size="3">Code</font></span>](https://github.com/Mukaffi28/Vashantor-A-Large-scale-Multilingual-Benchmark-Dataset)] [[<span style ="color:red"><font size="3">Dataset</font></span>](https://data.mendeley.com/datasets/bj5jgk878b/2)] [<a style="color:red;" href="#" onclick="$('#vashantor2023_bib').toggle();return false;"><font size="3">Citation bib</font></a>] 

<div id="vashantor2023_bib" class="bib" style="display:none;">
	<pre>
	  @misc{faria2023vashantor,
  			title={Vashantor: A Large-scale Multilingual Benchmark Dataset for Automated Translation of Bangla Regional Dialects to Bangla Language},
  			author={Fatema Tuj Johora Faria and Mukaffi Bin Moin and Ahmed Al Wase and Mehidi Ahmmed and Md. Rabius Sani and Tashreef Muhammad},
  			year={2023},
  			eprint={2311.11142},
  			archivePrefix={arXiv},
  			primaryClass={cs.CL}
			}
	</pre>
</div>

<div id="vashantor2023_abstract" class="abstract" style="display:none;">
	<p style="text-align:justify; color:black;font-family:Monaco;"> 
		<font size="3">
			The Bangla linguistic variety is a fascinating mix of regional dialects that adds to the cultural diversity of the Bangla-speaking community. Despite extensive study into translating Bangla to English, English to Bangla, and Banglish to Bangla in the past, there has been a noticeable gap in translating Bangla regional dialects into standard Bangla. In this study, we set out to fill this gap by creating a collection of 32,500 sentences, encompassing Bangla, Banglish, and English, representing five regional Bangla dialects. Our aim is to translate these regional dialects into standard Bangla and detect regions accurately. To achieve this, we proposed models known as mT5 and BanglaT5 for translating regional dialects into standard Bangla. Additionally, we employed mBERT and Bangla-bert-base to determine the specific regions from where these dialects originated. Our experimental results showed the highest BLEU score of 69.06 for Mymensingh regional dialects and the lowest BLEU score of 36.75 for Chittagong regional dialects. We also observed the lowest average word error rate of 0.1548 for Mymensingh regional dialects and the highest of 0.3385 for Chittagong regional dialects. For region detection, we achieved an accuracy of 85.86% for Bangla-bert-base and 84.36% for mBERT. This is the first large-scale investigation of Bangla regional dialects to Bangla machine translation. We believe our findings will not only pave the way for future work on Bangla regional dialects to Bangla machine translation, but will also be useful in solving similar language-related challenges in low-resource language conditions.
		</font>
	</p>
</div> 



<!-- Paper 13 -->
ðŸ“Œ [<span style="color:blue;font-family:Trebuchet MS;">**Classification of Potato Disease with Digital Image Processing Technique: A Hybrid Deep Learning Framework**</span>](https://ieeexplore.ieee.org/document/10099162)<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Authors</strong>: <strong style="color:green">Fatema Tuj Johora Faria,</strong> Mukaffi Bin Moin, Ahmed Al Wase, Md Rabius Sani, Khan Md Hasib, and Mohammad Shafiul Alam.</font>
</span>
<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Conference:</strong><em> 2023 IEEE 13th Annual Computing and Communication Workshop and Conference (CCWC) </em></font> ([CCWC 2023](https://ieee-ccwc.org/#))
</span>
<br>
[<a style="color:red;" href="#" onclick="$('#potato2023_abstract').toggle();return false;"><font size="3">Abstract</font></a>] [[<span style ="color:red"><font size="3">PDF</font></span>](https://www.researchgate.net/publication/370123763_Classification_of_Potato_Disease_with_Digital_Image_Processing_Technique_A_Hybrid_Deep_Learning_Framework)] [[<span style ="color:red"><font size="3">Code</font></span>](https://github.com/fatemafaria142/Classification-of-Potato-Disease-A-Hybrid-Deep-Learning-Framework)] [[<span style ="color:red"><font size="3">Dataset</font></span>](https://github.com/Mukaffi28/Potato-Disease)] [<a style="color:red;" href="#" onclick="$('#potato2023_bib').toggle();return false;"><font size="3">Citation bib</font></a>] 

<div id="potato2023_bib" class="bib" style="display:none;">
	<pre>
	  @INPROCEEDINGS{10099162,
  		author={Faria, Fatema Tuj Johora and Bin Moin, Mukaffi and Al Wase, Ahmed and Sani, Md. Rabius and Hasib, Khan Md and Alam, Mohammad Shafiul},
  		booktitle={2023 IEEE 13th Annual Computing and Communication Workshop and Conference (CCWC)}, 
  		title={Classification of Potato Disease with Digital Image Processing Technique: A Hybrid Deep Learning Framework}, 
  		year={2023},
  		volume={},
  		number={},
  		pages={0820-0826},
  		keywords={Fungi;Deep learning;Image processing;Digital images;Conferences;Stochastic processes;Training data;Deep learning;Image processing;MobileNet V2;LSTM;GRU;BiLSTM;Disease classification},
  		doi={10.1109/CCWC57344.2023.10099162}}
	</pre>
</div>

<div id="potato2023_abstract" class="abstract" style="display:none;">
	<p style="text-align:justify; color:black;font-family:Monaco;"> 
		<font size="3">
			Potatoes are among the major vegetables in agricultural regions, and it is farmed and utilized all over the world. Potatoes are a high-protein food with several health benefits, but there are numerous diseases associated with potatoes that hamper production. In this research, we developed a hybrid approach that employs image processing and combines MobileNet V2 with LSTM, GRU, and Bidirectional LSTM to evaluate potato disease classes known as Black Scurf, Common Scab, Blackleg, Dry Rot, Pink Rot, Healthy, and Miscellaneous. We examined the outcomes of each architecture after applying it independently to determine the optimal architecture configuration for categorizing potato diseases. In terms of accuracy, the results show that the hybrid MobileNet V2-GRU with Stochastic Gradient Descent optimizer strategy exceeds the other alternative. On the test dataset, we achieved 99% accuracy.
		</font>
	</p>
</div>



