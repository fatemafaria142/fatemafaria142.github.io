---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

<span style="font-family: 'Segoe UI', sans-serif; color: black;">
<div style="display: flex; flex-wrap: wrap; gap: 20px;">
  <div style="background-color: white; border-left: 5px solid #3b82f6; border-radius: 10px; padding: 25px; flex: 1 1 100%; max-width: 100%; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); transition: transform 0.2s ease, box-shadow 0.2s ease;" onmouseover="this.style.transform='scale(1.01)'; this.style.boxShadow='0 5px 10px rgba(0, 0, 0, 0.12)';" onmouseout="this.style.transform='scale(1)'; this.style.boxShadow='0 4px 6px rgba(0, 0, 0, 0.1)';">
    <ul style="font-family: 'Segoe UI', sans-serif; color: black; margin-top: 15px;">
      <li style="margin-bottom: 12px; list-style-type: none; position: relative; padding-left: 25px;">
        <span style="position: absolute; left: 0; color: #3b82f6; font-size: 0.9em;">■</span>
        Most recent publication updates can be found on my <a href="https://scholar.google.com/citations?user=LEken_4AAAAJ&hl=en" style="color: #389EDA; text-decoration: none;">Google Scholar</a> profile.
      </li>
      <li style="margin-bottom: 12px; list-style-type: none; position: relative; padding-left: 25px;">
        <span style="position: absolute; left: 0; color: #3b82f6; font-size: 0.9em;">■</span>
        [*] denotes equal contribution
      </li>
    </ul>
  </div>
</div>

<h2>2025</h2>
<hr>
<div style="display: flex; flex-wrap: wrap; gap: 20px;">
  <div style="background-color: white; border-left: 5px solid #3b82f6; border-radius: 10px; padding: 25px; flex: 1 1 100%; max-width: 100%; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); transition: transform 0.2s ease, box-shadow 0.2s ease;" onmouseover="this.style.transform='scale(1.01)'; this.style.boxShadow='0 5px 10px rgba(0, 0, 0, 0.12)';" onmouseout="this.style.transform='scale(1)'; this.style.boxShadow='0 4px 6px rgba(0, 0, 0, 0.1)';">
    <div style="background-color: #dbeafe; padding: 10px; border-radius: 5px; margin-bottom: 15px;">
      <span style="color: #1e3a8a; font-size: 1em; font-weight: bold;">MultiBanFakeDetect: Integrating Advanced Fusion Techniques for Multimodal Detection of Bangla Fake News in Under-Resourced Contexts</span>
    </div>
    <ul style="font-family: 'Segoe UI', sans-serif; color: black; margin-top: 15px;">
      <li style="margin-bottom: 12px; list-style-type: none; position: relative; padding-left: 25px;">
        <span style="position: absolute; left: 0; color: #3b82f6; font-size: 0.9em;">■</span>
        <b>Authors:</b> <span style="color: #10b981">Fatema Tuj Johora Faria</span>, Mukaffi Bin Moin, Zayeed Hasan, Md Arafat Alam Khandaker, Niful Islam, Khan Md Hasib, and M. F. Mridha <br/>
        <b>Journal:</b> <em>International Journal of Information Management Data Insights</em> <span style="background-color: #e6f4ea; color: #3b82f6; padding: 2px 8px; border-radius: 4px; font-size: 0.9em;">Q1</span> <br/>
        <div style="margin-top: 10px;">
          <a href="javascript:void(0)" onclick="document.getElementById('FakeNews2025_abstract').style.display = document.getElementById('FakeNews2025_abstract').style.display === 'none' ? 'block' : 'none';" style="background-color: #3b82f6; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Abstract</a>
          <a href="https://www.sciencedirect.com/science/article/pii/S2667096825000291" style="background-color: #ef4444; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">PDF</a>
          <a href="https://github.com/fatemafaria142/MultiBanFakeDetect-An-Extensive-Benchmark-Dataset-for-Multimodal-Bangla-Fake-News-Detection" style="background-color: #10b981; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Code</a>
          <a href="https://data.mendeley.com/datasets/k5pbz9795f/1" style="background-color: #f59e0b; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Dataset</a>
          <a href="javascript:void(0)" onclick="document.getElementById('FakeNews2025_bib').style.display = document.getElementById('FakeNews2025_bib').style.display === 'none' ? 'block' : 'none';" style="background-color: #8b5cf6; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Citation bib</a>
        </div>
      </li>
    </ul>
    <div id="FakeNews2025_bib" class="bib" style="display:none; font-family: 'Segoe UI', sans-serif; color: black; margin-top: 10px;">
      <pre>
@article{FARIA2025100347,
  title = {MultiBanFakeDetect: Integrating advanced fusion techniques for multimodal detection of Bangla fake news in under-resourced contexts},
  journal = {International Journal of Information Management Data Insights},
  volume = {5},
  number = {2},
  pages = {100347},
  year = {2025},
  issn = {2667-0968},
  doi = {https://doi.org/10.1016/j.jjimei.2025.100347},
  url = {https://www.sciencedirect.com/science/article/pii/S2667096825000291},
  author = {Fatema Tuj Johora Faria and Mukaffi Bin Moin and Zayeed Hasan and Md. Arafat Alam Khandaker and Niful Islam and Khan Md Hasib and M.F. Mridha},
  keywords = {Fake news detection, Multimodal dataset, Textual analysis, Visual analysis, Bangla language, Under-resource, Fusion techniques, Deep learning},
  abstract = {The rise of false news in recent years poses significant risks to society. As misinformation spreads rapidly, automated detection systems are essential to mitigate its impact. However, most existing methods rely solely on textual analysis, limiting their effectiveness. The challenge is further compounded by the lack of a large-scale, multimodal dataset for Bangla fake news detection, as existing datasets are either small or unimodal. To address this, we introduce MultiBanFakeDetect, a novel multimodal dataset integrating both textual and visual information. This dataset comprises manually curated real and fake news samples from various online sources. Additionally, we propose MultiFusionFake, a hybrid multimodal fake news detection framework that fuses text and image modalities using an Early Fusion approach while also comparing Late and Intermediate fusion techniques. Our experiments show that MultiFusionFake, combining DenseNet-169 and mBERT, achieves 79.69% accuracy, outperforming the text-only mBERT model’s 73.13%, reflecting a 6.56 percentage point improvement. These results underscore the advantages of multimodal over unimodal methods. To the best of our knowledge, this is the first study on multimodal fake news detection in the under-resourced Bangla context, offering a promising approach to combating online misinformation.}
}
      </pre>
    </div>
    <div id="FakeNews2025_abstract" class="abstract" style="display:none; font-family: 'Segoe UI', sans-serif; color: black; margin-top: 10px;">
      <p style="text-align: justify;">
        The rise of false news in recent years poses significant risks to society. As misinformation spreads rapidly, automated detection systems are essential to mitigate its impact. However, most existing methods rely solely on textual analysis, limiting their effectiveness. The challenge is further compounded by the lack of a large-scale, multimodal dataset for Bangla fake news detection, as existing datasets are either small or unimodal. To address this, we introduce MultiBanFakeDetect, a novel multimodal dataset integrating both textual and visual information. This dataset comprises manually curated real and fake news samples from various online sources. Additionally, we propose MultiFusionFake, a hybrid multimodal fake news detection framework that fuses text and image modalities using an Early Fusion approach while also comparing Late and Intermediate fusion techniques. Our experiments show that MultiFusionFake, combining DenseNet-169 and mBERT, achieves 79.69% accuracy, outperforming the text-only mBERT model’s 73.13%, reflecting a 6.56 percentage point improvement. These results underscore the advantages of multimodal over unimodal methods. To the best of our knowledge, this is the first study on multimodal fake news detection in the under-resourced Bangla context, offering a promising approach to combating online misinformation.
      </p>
    </div>
  </div>

  <div style="background-color: white; border-left: 5px solid #ef4444; border-radius: 10px; padding: 25px; flex: 1 1 100%; max-width: 100%; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); transition: transform 0.2s ease, box-shadow 0.2s ease;" onmouseover="this.style.transform='scale(1.01)'; this.style.boxShadow='0 5px 10px rgba(0, 0, 0, 0.12)';" onmouseout="this.style.transform='scale(1)'; this.style.boxShadow='0 4px 6px rgba(0, 0, 0, 0.1)';">
    <div style="background-color: #fee2e2; padding: 10px; border-radius: 5px; margin-bottom: 15px;">
      <span style="color: #7f1d1d; font-size: 1em; font-weight: bold;">SentimentFormer: A Transformer-Based Multi-Modal Fusion Framework for Enhanced Sentiment Analysis of Memes in Under-Resourced Bangla Language</span>
    </div>
    <ul style="font-family: 'Segoe UI', sans-serif; color: black; margin-top: 15px;">
      <li style="margin-bottom: 12px; list-style-type: none; position: relative; padding-left: 25px;">
        <span style="position: absolute; left: 0; color: #ef4444; font-size: 0.9em;">■</span>
        <b>Authors:</b> <span style="color: #10b981">Fatema Tuj Johora Faria</span>, Laith H Baniata, Mohammad H Baniata, Mohannad A Khair, Ahmed Ibrahim Bani Ata, Chayut Bunterngchit, and Sangwoo Kang <br/>
        <b>Journal:</b> <em>Electronics</em> <span style="background-color: #fee2e2; color: #ef4444; padding: 2px 8px; border-radius: 4px; font-size: 0.9em;">Q2</span> <br/>
        <div style="margin-top: 10px;">
          <a href="javascript:void(0)" onclick="document.getElementById('sentiment2025_abstract').style.display = document.getElementById('sentiment2025_abstract').style.display === 'none' ? 'block' : 'none';" style="background-color: #3b82f6; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Abstract</a>
          <a href="https://www.mdpi.com/2079-9292/14/4/799" style="background-color: #ef4444; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">PDF</a>
          <a href="https://github.com/fatemafaria142/SentimentFormer-A-Transformer-Based-Multi-Modal-Fusion-Framework-for-Sentiment-Analysis-of-Memes" style="background-color: #10b981; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Code</a>
          <a href="https://drive.google.com/file/d/12jxFuMz7jtE1kN9fi1ckspgHcKZhkT_B/view" style="background-color: #f59e0b; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Dataset</a>
          <a href="javascript:void(0)" onclick="document.getElementById('sentiment2025_bib').style.display = document.getElementById('sentiment2025_bib').style.display === 'none' ? 'block' : 'none';" style="background-color: #8b5cf6; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Citation bib</a>
        </div>
      </li>
    </ul>
    <div id="sentiment2025_bib" class="bib" style="display:none; font-family: 'Segoe UI', sans-serif; color: black; margin-top: 10px;">
      <pre>
@Article{electronics14040799,
  AUTHOR = {Faria, Fatema Tuj Johora and Baniata, Laith H. and Baniata, Mohammad H. and Khair, Mohannad A. and Bani Ata, Ahmed Ibrahim and Bunterngchit, Chayut and Kang, Sangwoo},
  TITLE = {SentimentFormer: A Transformer-Based Multimodal Fusion Framework for Enhanced Sentiment Analysis of Memes in Under-Resourced Bangla Language},
  JOURNAL = {Electronics},
  VOLUME = {14},
  YEAR = {2025},
  NUMBER = {4},
  ARTICLE-NUMBER = {799},
  URL = {https://www.mdpi.com/2079-9292/14/4/799},
  ISSN = {2079-9292},
  ABSTRACT = {Social media has increasingly relied on memes as a tool for expressing opinions, making meme sentiment analysis an emerging area of interest for researchers. While much of the research has focused on English-language memes, under-resourced languages, such as Bengali, have received limited attention. Given the surge in social media use, the need for sentiment analysis of memes in these languages has become critical. One of the primary challenges in this field is the lack of benchmark datasets, particularly in languages with fewer resources. To address this, we used the MemoSen dataset, designed for Bengali, which consists of 4368 memes annotated with three sentiment labels: positive, negative, and neutral. MemoSen is divided into training (70%), test (20%), and validation (10%) sets, with an imbalanced class distribution: 1349 memes in the positive class, 2728 in the negative class, and 291 in the neutral class. Our approach leverages advanced deep learning techniques for multimodal sentiment analysis in Bengali, introducing three hybrid approaches. SentimentTextFormer is a text-based, fine-tuned model that utilizes state-of-the-art transformer architectures to accurately extract sentiment-related insights from Bengali text, capturing nuanced linguistic features. SentimentImageFormer is an image-based model that employs cutting-edge transformer-based techniques for precise sentiment classification through visual data. Lastly, SentimentFormer is a hybrid model that seamlessly integrates both text and image modalities using fusion strategies. Early fusion combines textual and visual features at the input level, enabling the model to jointly learn from both modalities. Late fusion merges the outputs of separate text and image models, preserving their individual strengths for the final prediction. Intermediate fusion integrates textual and visual features at intermediate layers, refining their interactions during processing. These fusion strategies combine the strengths of both textual and visual data, enhancing sentiment analysis by exploiting complementary information from multiple sources. The performance of our models was evaluated using various accuracy metrics, with SentimentTextFormer achieving 73.31% accuracy and SentimentImageFormer attaining 64.72%. The hybrid model, SentimentFormer (SwiftFormer with mBERT), employing intermediate fusion, shows a notable improvement in accuracy, achieving 79.04%, outperforming SentimentTextFormer by 5.73% and SentimentImageFormer by 14.32%. Among the fusion strategies, SentimentFormer (SwiftFormer with mBERT) achieved the highest accuracy of 79.04%, highlighting the effectiveness of our fusion technique and the reliability of our multimodal framework in improving sentiment analysis accuracy across diverse modalities.},
  DOI = {10.3390/electronics14040799}
}
      </pre>
    </div>
    <div id="sentiment2025_abstract" class="abstract" style="display:none; font-family: 'Segoe UI', sans-serif; color: black; margin-top: 10px;">
      <p style="text-align: justify;">
        Social media has increasingly relied on memes as a tool for expressing opinions, making meme sentiment analysis an emerging area of interest for researchers. While much of the research has focused on English-language memes, under-resourced languages, such as Bengali, have received limited attention. Given the surge in social media use, the need for sentiment analysis of memes in these languages has become critical. One of the primary challenges in this field is the lack of benchmark datasets, particularly in languages with fewer resources. To address this, we used the MemoSen dataset, designed for Bengali, which consists of 4,368 memes annotated with three sentiment labels: positive, negative, and neutral. MemoSen is divided into training (70%), test (20%), and validation (10%) sets, with an imbalanced class distribution: 1,349 memes in the positive class, 2,728 in the negative class, and 291 in the neutral class. Our approach leverages advanced deep learning techniques for multimodal sentiment analysis in Bengali, introducing three hybrid approaches. SentimentTextFormer is a text-based, fine-tuned model that utilizes state-of-the-art transformer architectures to accurately extract sentiment-related insights from Bengali text, capturing nuanced linguistic features. SentimentImageFormer is an image-based model that employs cutting-edge transformer-based techniques for precise sentiment classification through visual data. Lastly, SentimentFormer is a hybrid model that seamlessly integrates both text and image modalities using fusion strategies. Early fusion combines textual and visual features at the input level, enabling the model to jointly learn from both modalities. Late fusion merges the outputs of separate text and image models, preserving their individual strengths for the final prediction. Intermediate fusion integrates textual and visual features at intermediate layers, refining their interactions during processing. These fusion strategies combine the strengths of both textual and visual data, enhancing sentiment analysis by exploiting complementary information from multiple sources. The performance of our models was evaluated using various accuracy metrics, with SentimentTextFormer achieving 73.31% accuracy and SentimentImageFormer attaining 64.72%. The hybrid model, SentimentFormer (SwiftFormer with mBERT), employing intermediate fusion, shows a notable improvement in accuracy, achieving 79.04%, outperforming SentimentTextFormer by 5.73% and SentimentImageFormer by 14.32%. Among the fusion strategies, SentimentFormer (SwiftFormer with mBERT) achieved the highest accuracy of 79.04%, highlighting the effectiveness of our fusion technique and the reliability of our multimodal framework in improving sentiment analysis accuracy across diverse modalities.
      </p>
    </div>
  </div>
</div>

<h2>2024</h2>
<hr>
<div style="display: flex; flex-wrap: wrap; gap: 20px;">
  <div style="background-color: white; border-left: 5px solid #8b5cf6; border-radius: 10px; padding: 25px; flex: 1 1 100%; max-width: 100%; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); transition: transform 0.2s ease, box-shadow 0.2s ease;" onmouseover="this.style.transform='scale(1.01)'; this.style.boxShadow='0 5px 10px rgba(0, 0, 0, 0.12)';" onmouseout="this.style.transform='scale(1)'; this.style.boxShadow='0 4px 6px rgba(0, 0, 0, 0.1)';">
    <div style="background-color: #ede9fe; padding: 10px; border-radius: 5px; margin-bottom: 15px;">
      <span style="color: #4c1d95; font-size: 1em; font-weight: bold;">Investigating the Predominance of Large Language Models in Low-Resource Bangla Language Over Transformer Models for Hate Speech Detection: A Comparative Analysis</span>
    </div>
    <ul style="font-family: 'Segoe UI', sans-serif; color: black; margin-top: 15px;">
      <li style="margin-bottom: 12px; list-style-type: none; position: relative; padding-left: 25px;">
        <span style="position: absolute; left: 0; color: #8b5cf6; font-size: 0.9em;">■</span>
        <b>Authors:</b> <span style="color: #10b981">Fatema Tuj Johora Faria</span>, Laith H. Baniata, and Sangwoo Kang <br/>
        <b>Journal:</b> <em>Mathematics</em> <span style="background-color: #ede9fe; color: #8b5cf6; padding: 2px 8px; border-radius: 4px; font-size: 0.9em;">Q1</span> <br/>
        <div style="margin-top: 10px;">
          <a href="javascript:void(0)" onclick="document.getElementById('hate2024_abstract').style.display = document.getElementById('hate2024_abstract').style.display === 'none' ? 'block' : 'none';" style="background-color: #3b82f6; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Abstract</a>
          <a href="https://www.mdpi.com/2227-7390/12/23/3687" style="background-color: #ef4444; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">PDF</a>
          <a href="https://github.com/fatemafaria142/Bangla-Hate-Speech-Detection" style="background-color: #10b981; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Code</a>
          <a href="https://www.kaggle.com/datasets/naurosromim/bdshs" style="background-color: #f59e0b; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Dataset</a>
          <a href="javascript:void(0)" onclick="document.getElementById('hate2024_bib').style.display = document.getElementById('hate2024_bib').style.display === 'none' ? 'block' : 'none';" style="background-color: #8b5cf6; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Citation bib</a>
        </div>
      </li>
    </ul>
    <div id="hate2024_bib" class="bib" style="display:none; font-family: 'Segoe UI', sans-serif; color: black; margin-top: 10px;">
      <pre>
@Article{math12233687,
  AUTHOR = {Faria, Fatema Tuj Johora and Baniata, Laith H. and Kang, Sangwoo},
  TITLE = {Investigating the Predominance of Large Language Models in Low-Resource Bangla Language over Transformer Models for Hate Speech Detection: A Comparative Analysis},
  JOURNAL = {Mathematics},
  VOLUME = {12},
  YEAR = {2024},
  NUMBER = {23},
  ARTICLE-NUMBER = {3687},
  URL = {https://www.mdpi.com/2227-7390/12/23/3687},
  ISSN = {2227-7390},
  DOI = {10.3390/math12233687}
}
      </pre>
    </div>
    <div id="hate2024_abstract" class="abstract" style="display:none; font-family: 'Segoe UI', sans-serif; color: black; margin-top: 10px;">
      <p style="text-align: justify;">
        The rise in abusive language on social media is a significant threat to mental health and social cohesion. For Bengali speakers, the need for effective detection is critical. However, current methods fall short in addressing the massive volume of content. Improved techniques are urgently needed to combat online hate speech in Bengali. Traditional machine learning techniques, while useful, often require large, linguistically diverse datasets to train models effectively. This paper addresses the urgent need for improved hate speech detection methods in Bengali, aiming to fill the existing research gap. Contextual understanding is crucial in differentiating between harmful speech and benign expressions. Large language models (LLMs) have shown state-of-the-art performance in various natural language tasks due to their extensive training on vast amounts of data. We explore the application of LLMs, specifically GPT-3.5 Turbo and Gemini 1.5 Pro, for Bengali hate speech detection using Zero-Shot and Few-Shot Learning approaches. Unlike conventional methods, Zero-Shot Learning identifies hate speech without task-specific training data, making it highly adaptable to new datasets and languages. Few-Shot Learning, on the other hand, requires minimal labeled examples, allowing for efficient model training with limited resources. Our experimental results show that LLMs outperform traditional approaches. In this study, we evaluate GPT-3.5 Turbo and Gemini 1.5 Pro on multiple datasets. To further enhance our study, we consider the distribution of comments in different datasets and the challenge of class imbalance, which can affect model performance. The BD-SHS dataset consists of 35,197 comments in the training set, 7542 in the validation set, and 7542 in the test set. The Bengali Hate Speech Dataset v1.0 and v2.0 include comments distributed across various hate categories: personal hate (629), political hate (1771), religious hate (502), geopolitical hate (1179), and gender abusive hate (316). The Bengali Hate Dataset comprises 7500 non-hate and 7500 hate comments. GPT-3.5 Turbo achieved impressive results with 97.33%, 98.42%, and 98.53% accuracy. In contrast, Gemini 1.5 Pro showed lower performance across all datasets. Specifically, GPT-3.5 Turbo excelled with significantly higher accuracy compared to Gemini 1.5 Pro. These outcomes highlight a 6.28% increase in accuracy compared to traditional methods, which achieved 92.25%. Our research contributes to the growing body of literature on LLM applications in natural language processing, particularly in the context of low-resource languages.
      </p>
    </div>
  </div>

  <div style="background-color: white; border-left: 5px solid #10b981; border-radius: 10px; padding: 25px; flex: 1 1 100%; max-width: 100%; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); transition: transform 0.2s ease, box-shadow 0.2s ease;" onmouseover="this.style.transform='scale(1.01)'; this.style.boxShadow='0 5px 10px rgba(0, 0, 0, 0.12)';" onmouseout="this.style.transform='scale(1)'; this.style.boxShadow='0 4px 6px rgba(0, 0, 0, 0.1)';">
    <div style="background-color: #e6f4ea; padding: 10px; border-radius: 5px; margin-bottom: 15px;">
      <span style="color: #065f46; font-size: 1em; font-weight: bold;">Motamot: A Dataset for Revealing the Supremacy of Large Language Models Over Transformer Models in Bengali Political Sentiment Analysis</span>
    </div>
    <ul style="font-family: 'Segoe UI', sans-serif; color: black; margin-top: 15px;">
      <li style="margin-bottom: 12px; list-style-type: none; position: relative; padding-left: 25px;">
        <span style="position: absolute; left: 0; color: #10b981; font-size: 0.9em;">■</span>
        <b>Authors:</b> <span style="color: #10b981">Fatema Tuj Johora Faria*</span>, Mukaffi Bin Moin*, Rabeya Islam Mumu, Md Mahabubul Alam Abir, Abrar Nawar Alfy, and Mohammad Shafiul Alam <br/>
        <b>Conference:</b> <em>The IEEE Region 10 Symposium (TENSYMP 2024)</em> <br/>
        <div style="margin-top: 10px;">
          <a href="javascript:void(0)" onclick="document.getElementById('Motamot2024_abstract').style.display = document.getElementById('Motamot2024_abstract').style.display === 'none' ? 'block' : 'none';" style="background-color: #3b82f6; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Abstract</a>
          <a href="https://arxiv.org/pdf/2407.19528" style="background-color: #ef4444; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">PDF</a>
          <a href="https://github.com/Mukaffi28/Bengali-Political-Sentiment-Analysis" style="background-color: #10b981; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Code</a>
          <a href="https://data.mendeley.com/datasets/hdhnrrwdz2/1" style="background-color: #f59e0b; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Dataset</a>
          <a href="javascript:void(0)" onclick="document.getElementById('Motamot2024_bib').style.display = document.getElementById('Motamot2024_bib').style.display === 'none' ? 'block' : 'none';" style="background-color: #8b5cf6; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Citation bib</a>
        </div>
      </li>
    </ul>
    <div id="Motamot2024_bib" class="bib" style="display:none; font-family: 'Segoe UI', sans-serif; color: black; margin-top: 10px;">
      <pre>
@INPROCEEDINGS{10752197,
  author={Johora Faria, Fatema Tuj and Moin, Mukaffi Bin and Mumu, Rabeya Islam and Alam Abir, Md Mahabubul and Alfy, Abrar Nawar and Alam, Mohammad Shafiul},
  booktitle={2024 IEEE Region 10 Symposium (TENSYMP)},
  title={Motamot: A Dataset for Revealing the Supremacy of Large Language Models Over Transformer Models in Bengali Political Sentiment Analysis},
  year={2024},
  volume={},
  number={},
  pages={1-8},
  keywords={Sentiment analysis;Analytical models;Accuracy;Voting;Large language models;Transformers;Market research;Few shot learning;Portals;IEEE Regions;Political Sentiment Analysis;Pre-trained Language Models;Large Language Models;Gemini 1.5 Pro;GPT 3.5 Turbo;Zero-shot Learning;Fewshot Learning;Low-resource Language},
  doi={10.1109/TENSYMP61132.2024.10752197}
}
      </pre>
    </div>
    <div id="Motamot2024_abstract" class="abstract" style="display:none; font-family: 'Segoe UI', sans-serif; color: black; margin-top: 10px;">
      <p style="text-align: justify;">
        Sentiment analysis is the process of identifying and categorizing people's emotions or opinions regarding various topics. Analyzing political sentiment is critical for understanding the complexities of public opinion processes, especially during election seasons. It gives significant information on voter preferences, attitudes, and current trends. In this study, we investigate political sentiment analysis during Bangladeshi elections, specifically examining how effectively Pre-trained Language Models (PLMs) and Large Language Models (LLMs) capture complex sentiment characteristics. Our study centers on the creation of the "Motamot" dataset, comprising 7,058 instances annotated with positive and negative sentiments, sourced from diverse online newspaper portals, forming a comprehensive resource for political sentiment analysis. We meticulously evaluate the performance of various PLMs including BanglaBERT, Bangla BERT Base, XLM-RoBERTa, mBERT, and sahajBERT, alongside LLMs such as Gemini 1.5 Pro and GPT 3.5 Turbo. Moreover, we explore zero-shot and few-shot learning strategies to enhance our understanding of political sentiment analysis methodologies. Our findings underscore BanglaBERT's commendable accuracy of 88.10% among PLMs. However, the exploration into LLMs reveals even more promising results. Through the adept application of Few-Shot learning techniques, Gemini 1.5 Pro achieves an impressive accuracy of 96.33%, surpassing the remarkable performance of GPT 3.5 Turbo, which stands at 94%. This underscores Gemini 1.5 Pro's status as the superior performer in this comparison.
      </p>
    </div>
  </div>

  <div style="background-color: white; border-left: 5px solid #3b82f6; border-radius: 10px; padding: 25px; flex: 1 1 100%; max-width: 100%; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); transition: transform 0.2s ease, box-shadow 0.2s ease;" onmouseover="this.style.transform='scale(1.01)'; this.style.boxShadow='0 5px 10px rgba(0, 0, 0, 0.12)';" onmouseout="this.style.transform='scale(1)'; this.style.boxShadow='0 4px 6px rgba(0, 0, 0, 0.1)';">
    <div style="background-color: #dbeafe; padding: 10px; border-radius: 5px; margin-bottom: 15px;">
      <span style="color: #1e3a8a; font-size: 1em; font-weight: bold;">BanglaCalamityMMD: A Comprehensive Benchmark Dataset for Multimodal Disaster Identification in the Low-Resource Bangla Language</span>
    </div>
    <ul style="font-family: 'Segoe UI', sans-serif; color: black; margin-top: 15px;">
      <li style="margin-bottom: 12px; list-style-type: none; position: relative; padding-left: 25px;">
        <span style="position: absolute; left: 0; color: #3b82f6; font-size: 0.9em;">■</span>
        <b>Authors:</b> <span style="color: #10b981">Fatema Tuj Johora Faria</span>, Mukaffi Bin Moin, Busra Kamal Rafa, Swarnajit Saha, Md. Mahfuzur Rahman, Khan Md Hasib, and M. F. Mridha <br/>
        <b>Journal:</b> <em>Under Review in International Journal of Disaster Risk Reduction</em> <span style="background-color: #e6f4ea; color: #3b82f6; padding: 2px 8px; border-radius: 4px; font-size: 0.9em;">Q1</span> <br/>
        <div style="margin-top: 10px;">
          <a href="https://github.com/Mukaffi28/BanglaCalamityMMD-A-Comprehensive-Benchmark-Dataset-for-Multimodal-Disaster-Identification" style="background-color: #10b981; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Code</a>
          <a href="https://data.mendeley.com/datasets/7dggbjn5sd/1" style="background-color: #f59e0b; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Dataset</a>
        </div>
      </li>
    </ul>
  </div>

  <div style="background-color: white; border-left: 5px solid #ef4444; border-radius: 10px; padding: 25px; flex: 1 1 100%; max-width: 100%; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); transition: transform 0.2s ease, box-shadow 0.2s ease;" onmouseover="this.style.transform='scale(1.01)'; this.style.boxShadow='0 5px 10px rgba(0, 0, 0, 0.12)';" onmouseout="this.style.transform='scale(1)'; this.style.boxShadow='0 4px 6px rgba(0, 0, 0, 0.1)';">
    <div style="background-color: #fee2e2; padding: 10px; border-radius: 5px; margin-bottom: 15px;">
      <span style="color: #7f1d1d; font-size: 1em; font-weight: bold;">BanglaMemeEvidence: A Multimodal Benchmark Dataset for Explanatory Evidence Detection in Bengali Memes</span>
    </div>
    <ul style="font-family: 'Segoe UI', sans-serif; color: black; margin-top: 15px;">
      <li style="margin-bottom: 12px; list-style-type: none; position: relative; padding-left: 25px;">
        <span style="position: absolute; left: 0; color: #ef4444; font-size: 0.9em;">■</span>
        <b>Authors:</b> <span style="color: #10b981">Fatema Tuj Johora Faria</span>, Mukaffi Bin Moin, Asif Iftekher Fahim, Pronay Debnath, and Faisal Muhammad Shah <br/>
        <b>Conference:</b> <em>Under Review in 2025 9th International Conference on Vision, Image and Signal Processing</em> <br/>
        <div style="margin-top: 10px;"></div>
      </li>
    </ul>
  </div>

  <div style="background-color: white; border-left: 5px solid #8b5cf6; border-radius: 10px; padding: 25px; flex: 1 1 100%; max-width: 100%; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); transition: transform 0.2s ease, box-shadow 0.2s ease;" onmouseover="this.style.transform='scale(1.01)'; this.style.boxShadow='0 5px 10px rgba(0, 0, 0, 0.12)';" onmouseout="this.style.transform='scale(1)'; this.style.boxShadow='0 4px 6px rgba(0, 0, 0, 0.1)';">
    <div style="background-color: #ede9fe; padding: 10px; border-radius: 5px; margin-bottom: 15px;">
      <span style="color: #4c1d95; font-size: 1em; font-weight: bold;">Enhancing Bangla NLP Tasks with LLMs: A Study on Few-Shot Learning, RAG, and Fine-Tuning Techniques</span>
    </div>
    <ul style="font-family: 'Segoe UI', sans-serif; color: black; margin-top: 15px;">
      <li style="margin-bottom: 12px; list-style-type: none; position: relative; padding-left: 25px;">
        <span style="position: absolute; left: 0; color: #8b5cf6; font-size: 0.9em;">■</span>
        <b>Authors:</b> Saidur Rahman Sujon, Ahmadul Karim Chowdhury, <span style="color: #10b981">Fatema Tuj Johora Faria</span>, Mukaffi Bin Moin, and Faisal Muhammad Shah <br/>
        <b>Conference:</b> <em>Under Review in 2025 IEEE 9th International Conference on Software Engineering & Computer Systems</em> <br/>
        <div style="margin-top: 10px;"></div>
      </li>
    </ul>
  </div>

  <div style="background-color: white; border-left: 5px solid #10b981; border-radius: 10px; padding: 25px; flex: 1 1 100%; max-width: 100%; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); transition: transform 0.2s ease, box-shadow 0.2s ease;" onmouseover="this.style.transform='scale(1.01)'; this.style.boxShadow='0 5px 10px rgba(0, 0, 0, 0.12)';" onmouseout="this.style.transform='scale(1)'; this.style.boxShadow='0 4px 6px rgba(0, 0, 0, 0.1)';">
    <div style="background-color: #e6f4ea; padding: 10px; border-radius: 5px; margin-bottom: 15px;">
      <span style="color: #065f46; font-size: 1em; font-weight: bold;">Uddessho: An Extensive Benchmark Dataset for Multimodal Author Intent Classification in Low-Resource Bangla Language</span>
    </div>
    <ul style="font-family: 'Segoe UI', sans-serif; color: black; margin-top: 15px;">
      <li style="margin-bottom: 12px; list-style-type: none; position: relative; padding-left: 25px;">
        <span style="position: absolute; left: 0; color: #10b981; font-size: 0.9em;">■</span>
        <b>Authors:</b> <span style="color: #10b981">Fatema Tuj Johora Faria</span>, Mukaffi Bin Moin, Md. Mahfuzur Rahman, Md Morshed Alam Shanto, Asif Iftekher Fahim, and Md. Moinul Hoque <br/>
        <b>Conference:</b> <em>18th International Conference on Information Technology and Applications (ICITA 2024)</em> <br/>
        <div style="margin-top: 10px;">
          <a href="javascript:void(0)" onclick="document.getElementById('Uddessho2024_abstract').style.display = document.getElementById('Uddessho2024_abstract').style.display === 'none' ? 'block' : 'none';" style="background-color: #3b82f6; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Abstract</a>
          <a href="https://arxiv.org/pdf/2409.09504" style="background-color: #ef4444; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">PDF</a>
          <a href="https://github.com/fatemafaria142/Uddessho-An-Benchmark-Dataset-for-Multimodal-Author-Intent-Classification-in-Bangla-Language" style="background-color: #10b981; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Code</a>
          <a href="https://data.mendeley.com/datasets/mzxmt8tfjs/1" style="background-color: #f59e0b; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Dataset</a>
          <a href="javascript:void(0)" onclick="document.getElementById('Uddessho2024_bib').style.display = document.getElementById('Uddessho2024_bib').style.display === 'none' ? 'block' : 'none';" style="background-color: #8b5cf6; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Citation bib</a>
        </div>
      </li>
    </ul>
    <div id="Uddessho2024_bib" class="bib" style="display:none; font-family: 'Segoe UI', sans-serif; color: black; margin-top: 10px;">
      <pre>
@misc{faria2024uddesshoextensivebenchmarkdataset,
  title={Uddessho: An Extensive Benchmark Dataset for Multimodal Author Intent Classification in Low-Resource Bangla Language},
  author={Fatema Tuj Johora Faria and Mukaffi Bin Moin and Md. Mahfuzur Rahman and Md Morshed Alam Shanto and Asif Iftekher Fahim and Md. Moinul Hoque},
  year={2024},
  eprint={2409.09504},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2409.09504},
}
      </pre>
    </div>
    <div id="Uddessho2024_abstract" class="abstract" style="display:none; font-family: 'Segoe UI', sans-serif; color: black; margin-top: 10px;">
      <p style="text-align: justify;">
        With the increasing popularity of daily information sharing and acquisition on the Internet, this paper introduces an innovative approach for intent classification in Bangla language, focusing on social media posts where individuals share their thoughts and opinions. The proposed method leverages multimodal data with particular emphasis on authorship identification, aiming to understand the underlying purpose behind textual content, especially in the context of varied user-generated posts on social media. Current methods often face challenges in low-resource languages like Bangla, particularly when author traits intricately link with intent, as observed in social media posts. To address this, we present the Multimodal-based Author Bangla Intent Classification (MABIC) framework, utilizing text and images to gain deeper insights into the conveyed intentions. We have created a dataset named "Uddessho," comprising 3,048 instances sourced from social media. Our methodology comprises two approaches for classifying textual intent and multimodal author intent, incorporating early fusion and late fusion techniques. In our experiments, the unimodal approach achieved an accuracy of 64.53% in interpreting Bangla textual intent. In contrast, our multimodal approach significantly outperformed traditional unimodal methods, achieving an accuracy of 76.19%. This represents an improvement of 11.66%. To our best knowledge, this is the first research work on multimodal-based author intent classification for low-resource Bangla language social media posts.
      </p>
    </div>
  </div>

  <div style="background-color: white; border-left: 5px solid #3b82f6; border-radius: 10px; padding: 25px; flex: 1 1 100%; max-width: 100%; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); transition: transform 0.2s ease, box-shadow 0.2s ease;" onmouseover="this.style.transform='scale(1.01)'; this.style.boxShadow='0 5px 10px rgba(0, 0, 0, 0.12)';" onmouseout="this.style.transform='scale(1)'; this.style.boxShadow='0 4px 6px rgba(0, 0, 0, 0.1)';">
    <div style="background-color: #dbeafe; padding: 10px; border-radius: 5px; margin-bottom: 15px;">
      <span style="color: #1e3a8a; font-size: 1em; font-weight: bold;">PotatoGANs: Utilizing Generative Adversarial Networks, Instance Segmentation, and Explainable AI for Enhanced Potato Disease Identification and Classification</span>
    </div>
    <ul style="font-family: 'Segoe UI', sans-serif; color: black; margin-top: 15px;">
      <li style="margin-bottom: 12px; list-style-type: none; position: relative; padding-left: 25px;">
        <span style="position: absolute; left: 0; color: #3b82f6; font-size: 0.9em;">■</span>
        <b>Authors:</b> <span style="color: #10b981">Fatema Tuj Johora Faria*</span>, Mukaffi Bin Moin*, Mohammad Shafiul Alam*, Ahmed Al Wase, Md. Rabius Sani, and Khan Md Hasib <br/>
        <b>Conference:</b> <em>Under Review in 11th IEEE International Conference on Sustainable Technology and Engineering</em> <br/>
        <div style="margin-top: 10px;">
          <a href="javascript:void(0)" onclick="document.getElementById('Potato2024_abstract').style.display = document.getElementById('Potato2024_abstract').style.display === 'none' ? 'block' : 'none';" style="background-color: #3b82f6; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Abstract</a>
          <a href="https://arxiv.org/pdf/2405.07332" style="background-color: #ef4444; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">PDF</a>
          <a href="https://github.com/Mukaffi28/ExplainableAI-PotatoGAN-Cutting-Edge-Disease-Identification-for-Potatoes" style="background-color: #10b981; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Code</a>
          <a href="javascript:void(0)" onclick="document.getElementById('Potato2024_bib').style.display = document.getElementById('Potato2024_bib').style.display === 'none' ? 'block' : 'none';" style="background-color: #8b5cf6; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Citation bib</a>
        </div>
      </li>
    </ul>
    <div id="Potato2024_bib" class="bib" style="display:none; font-family: 'Segoe UI', sans-serif; color: black; margin-top: 10px;">
      <pre>
@misc{faria2025potatogansutilizinggenerativeadversarial,
  title={PotatoGANs: Utilizing Generative Adversarial Networks, Instance Segmentation, and Explainable AI for Enhanced Potato Disease Identification and Classification},
  author={Fatema Tuj Johora Faria and Mukaffi Bin Moin and Mohammad Shafiul Alam and Ahmed Al Wase and Md. Rabius Sani and Khan Md Hasib},
  year={2025},
  eprint={2405.07332},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2405.07332},
}
      </pre>
    </div>
    <div id="Potato2024_abstract" class="abstract" style="display:none; font-family: 'Segoe UI', sans-serif; color: black; margin-top: 10px;">
      <p style="text-align: justify;">
        Numerous applications have resulted from the automation of agricultural disease segmentation using deep learning techniques. However, when applied to new conditions, these applications frequently face the difficulty of overfitting, resulting in lower segmentation performance. In the context of potato farming, where diseases have a large influence on yields, it is critical for the agricultural economy to quickly and properly identify these diseases. Traditional data augmentation approaches, such as rotation, flip, and translation, have limitations and frequently fail to provide strong generalization results. To address these issues, our research employs a novel approach termed as PotatoGANs. In this novel data augmentation approach, two types of Generative Adversarial Networks (GANs) are utilized to generate synthetic potato disease images from healthy potato images. This approach not only expands the dataset but also adds variety, which helps to enhance model generalization. Using the Inception score as a measure, our experiments show the better quality and realisticness of the images created by PotatoGANs, emphasizing their capacity to resemble real disease images closely. The CycleGAN model outperforms the Pix2Pix GAN model in terms of image quality, as evidenced by its higher IS scores CycleGAN achieves higher Inception scores (IS) of 1.2001 and 1.0900 for black scurf and common scab, respectively. This synthetic data can significantly improve the training of large neural networks. It also reduces data collection costs while enhancing data diversity and generalization capabilities. Our work improves interpretability by combining three gradient-based Explainable AI algorithms (GradCAM, GradCAM++, and ScoreCAM) with three distinct CNN architectures (DenseNet169, Resnet152 V2, InceptionResNet V2) for potato disease classification.
      </p>
    </div>
  </div>

  <div style="background-color: white; border-left: 5px solid #ef4444; border-radius: 10px; padding: 25px; flex: 1 1 100%; max-width: 100%; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); transition: transform 0.2s ease, box-shadow 0.2s ease;" onmouseover="this.style.transform='scale(1.01)'; this.style.boxShadow='0 5px 10px rgba(0, 0, 0, 0.12)';" onmouseout="this.style.transform='scale(1)'; this.style.boxShadow='0 4px 6px rgba(0, 0, 0, 0.1)';">
    <div style="background-color: #fee2e2; padding: 10px; border-radius: 5px; margin-bottom: 15px;">
      <span style="color: #7f1d1d; font-size: 1em; font-weight: bold;">Explainable Convolutional Neural Networks for Retinal Fundus Classification and Cutting-Edge Segmentation Models for Retinal Blood Vessels from Fundus Images</span>
    </div>
    <ul style="font-family: 'Segoe UI', sans-serif; color: black; margin-top: 15px;">
      <li style="margin-bottom: 12px; list-style-type: none; position: relative; padding-left: 25px;">
        <span style="position: absolute; left: 0; color: #ef4444; font-size: 0.9em;">■</span>
        <b>Authors:</b> <span style="color: #10b981">Fatema Tuj Johora Faria</span>, Mukaffi Bin Moin, Pronay Debnath, Asif Iftekher Fahim, and Faisal Muhammad Shah <br/>
        <b>Journal:</b> <em>Under Review in Journal of Visual Communication and Image Representation</em> <span style="background-color: #fee2e2; color: #ef4444; padding: 2px 8px; border-radius: 4px; font-size: 0.9em;">Q1</span> <br/>
        <div style="margin-top: 10px;">
          <a href="javascript:void(0)" onclick="document.getElementById('Retina2024_abstract').style.display = document.getElementById('Retina2024_abstract').style.display === 'none' ? 'block' : 'none';" style="background-color: #3b82f6; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Abstract</a>
          <a href="https://arxiv.org/pdf/2405.07338" style="background-color: #ef4444; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">PDF</a>
          <a href="https://github.com/fatemafaria142/Retinal-Fundus-Classification-using-XAI-and-Segmentation" style="background-color: #10b981; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Code</a>
          <a href="javascript:void(0)" onclick="document.getElementById('Retina2024_bib').style.display = document.getElementById('Retina2024_bib').style.display === 'none' ? 'block' : 'none';" style="background-color: #8b5cf6; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Citation bib</a>
        </div>
      </li>
    </ul>
    <div id="Retina2024_bib" class="bib" style="display:none; font-family: 'Segoe UI', sans-serif; color: black; margin-top: 10px;">
      <pre>
@misc{faria2024explainableconvolutionalneuralnetworks,
  title={Explainable Convolutional Neural Networks for Retinal Fundus Classification and Cutting-Edge Segmentation Models for Retinal Blood Vessels from Fundus Images},
  author={Fatema Tuj Johora Faria and Mukaffi Bin Moin and Pronay Debnath and Asif Iftekher Fahim and Faisal Muhammad Shah},
  year={2024},
  eprint={2405.07338},
  archivePrefix={arXiv},
  primaryClass={eess.IV},
  url={https://arxiv.org/abs/2405.07338},
}
      </pre>
    </div>
    <div id="Retina2024_abstract" class="abstract" style="display:none; font-family: 'Segoe UI', sans-serif; color: black; margin-top: 10px;">
      <p style="text-align: justify;">
        Our research focuses on the critical field of early diagnosis of disease by examining retinal blood vessels in fundus images. While automatic segmentation of retinal blood vessels holds promise for early detection, accurate analysis remains challenging due to the limitations of existing methods, which often lack discrimination power and are susceptible to influences from pathological regions. Our research in fundus image analysis advances deep learning-based classification using eight pre-trained CNN models. To enhance interpretability, we utilize Explainable AI techniques such as Grad-CAM, Grad-CAM++, Score-CAM, Faster Score-CAM, and Layer CAM. These techniques illuminate the decision-making processes of the models, fostering transparency and trust in their predictions. Expanding our exploration, we investigate ten models, including TransUNet with ResNet backbones, Attention U-Net with DenseNet and ResNet backbones, and Swin-UNET. Incorporating diverse architectures such as ResNet50V2, ResNet101V2, ResNet152V2, and DenseNet121 among others, this comprehensive study deepens our insights into attention mechanisms for enhanced fundus image analysis. Among the evaluated models for fundus image classification, ResNet101 emerged with the highest accuracy, achieving an impressive 94.17%. On the other end of the spectrum, EfficientNetB0 exhibited the lowest accuracy among the models, achieving a score of 88.33%. Furthermore, in the domain of fundus image segmentation, Swin-Unet demonstrated a Mean Pixel Accuracy of 86.19%, showcasing its effectiveness in accurately delineating regions of interest within fundus images. Conversely, Attention U-Net with DenseNet201 backbone exhibited the lowest Mean Pixel Accuracy among the evaluated models, achieving a score of 75.87%.
      </p>
    </div>
  </div>

<div style="display: flex; flex-wrap: wrap; gap: 20px;">
  <div style="background-color: white; border-left: 5px solid #8b5cf6; border-radius: 10px; padding: 25px; flex: 1 1 100%; max-width: 100%; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); transition: transform 0.2s ease, box-shadow 0.2s ease;" onmouseover="this.style.transform='scale(1.01)'; this.style.boxShadow='0 5px 10px rgba(0, 0, 0, 0.12)';" onmouseout="this.style.transform='scale(1)'; this.style.boxShadow='0 4px 6px rgba(0, 0, 0, 0.1)';">
    <div style="background-color: #ede9fe; padding: 10px; border-radius: 5px; margin-bottom: 15px;">
      <span style="color: #4c1d95; font-size: 1em; font-weight: bold;">Unraveling the Dominance of Large Language Models Over Transformer Models for Bangla Natural Language Inference: A Comprehensive Study</span>
    </div>
    <ul style="font-family: 'Segoe UI', sans-serif; color: black; margin-top: 15px;">
      <li style="margin-bottom: 12px; list-style-type: none; position: relative; padding-left: 25px;">
        <span style="position: absolute; left: 0; color: #8b5cf6; font-size: 0.9em;">■</span>
        <b>Authors:</b> <span style="color: #10b981">Fatema Tuj Johora Faria</span>, Mukaffi Bin Moin, Asif Iftekher Fahim, Pronay Debnath, and Faisal Muhammad Shah <br/>
        <b>Conference:</b> <em>4th International Conference on Computing and Communication Networks (ICCCNet-2024)</em> <br/>
        <div style="margin-top: 10px;">
          <a href="javascript:void(0)" onclick="document.getElementById('NLI2024_abstract').style.display = document.getElementById('NLI2024_abstract').style.display === 'none' ? 'block' : 'none';" style="background-color: #3b82f6; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Abstract</a>
          <a href="https://arxiv.org/pdf/2405.02937" style="background-color: #ef4444; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">PDF</a>
          <a href="https://github.com/fatemafaria142/Large-Language-Models-Over-Transformer-Models-for-Bangla-NLI" style="background-color: #10b981; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Code</a>
          <a href="javascript:void(0)" onclick="document.getElementById('NLI2024_bib').style.display = document.getElementById('NLI2024_bib').style.display === 'none' ? 'block' : 'none';" style="background-color: #8b5cf6; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Citation bib</a>
        </div>
      </li>
    </ul>
    <div id="NLI2024_bib" class="bib" style="display:none; font-family: 'Segoe UI', sans-serif; color: black; margin-top: 10px;">
      <pre>
@misc{faria2024unravelingdominancelargelanguage,
  title={Unraveling the Dominance of Large Language Models Over Transformer Models for Bangla Natural Language Inference: A Comprehensive Study},
  author={Fatema Tuj Johora Faria and Mukaffi Bin Moin and Asif Iftekher Fahim and Pronay Debnath and Faisal Muhammad Shah},
  year={2024},
  eprint={2405.02937},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2405.02937},
}
      </pre>
    </div>
    <div id="NLI2024_abstract" class="abstract" style="display:none; font-family: 'Segoe UI', sans-serif; color: black; margin-top: 10px;">
      <p style="text-align: justify;">
        Natural Language Inference (NLI) is a cornerstone task in natural language processing, enabling machines to understand and reason about the semantic relationships between pairs of sentences. While significant progress has been made in high-resource languages like English, low-resource languages such as Bangla remain underexplored due to limited datasets and computational resources. This study investigates the performance of Large Language Models (LLMs) compared to traditional Transformer-based models for Bangla NLI. We leverage a comprehensive dataset and evaluate models such as GPT-3.5 Turbo, Gemini 1.5 Pro, BanglaBERT, and mBERT using zero-shot and few-shot learning approaches. Our results demonstrate that LLMs, particularly GPT-3.5 Turbo, achieve superior performance, with an accuracy of 92.15% in few-shot settings, outperforming Transformer models like BanglaBERT (85.67%) by 6.48%. This highlights the efficacy of LLMs in handling low-resource language tasks with minimal training data. The study also explores the impact of dataset size and class imbalance, providing insights into optimizing NLI systems for Bangla.
      </p>
    </div>
  </div>

  <div style="background-color: white; border-left: 5px solid #10b981; border-radius: 10px; padding: 25px; flex: 1 1 100%; max-width: 100%; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); transition: transform 0.2s ease, box-shadow 0.2s ease;" onmouseover="this.style.transform='scale(1.01)'; this.style.boxShadow='0 5px 10px rgba(0, 0, 0, 0.12)';" onmouseout="this.style.transform='scale(1)'; this.style.boxShadow='0 4px 6px rgba(0, 0, 0, 0.1)';">
    <div style="background-color: #e6f4ea; padding: 10px; border-radius: 5px; margin-bottom: 15px;">
      <span style="color: #065f46; font-size: 1em; font-weight: bold;">Exploring Explainable AI Techniques for Improved Interpretability in Lung and Colon Cancer Classification</span>
    </div>
    <ul style="font-family: 'Segoe UI', sans-serif; color: black; margin-top: 15px;">
      <li style="margin-bottom: 12px; list-style-type: none; position: relative; padding-left: 25px;">
        <span style="position: absolute; left: 0; color: #10b981; font-size: 0.9em;">■</span>
        <b>Authors:</b> Mukaffi Bin Moin, <span style="color: #10b981">Fatema Tuj Johora Faria</span>, Swarnajit Saha, Busra Kamal Rafa, and Mohammad Shafiul Alam <br/>
        <b>Conference:</b> <em>4th International Conference on Computing and Communication Networks (ICCCNet-2024)</em> <br/>
        <div style="margin-top: 10px;">
          <a href="javascript:void(0)" onclick="document.getElementById('Cancer2024_abstract').style.display = document.getElementById('Cancer2024_abstract').style.display === 'none' ? 'block' : 'none';" style="background-color: #3b82f6; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Abstract</a>
          <a href="https://arxiv.org/pdf/2405.07340" style="background-color: #ef4444; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">PDF</a>
          <a href="https://github.com/Mukaffi28/Explainable-AI-for-Lung-and-Colon-Cancer-Classification" style="background-color: #10b981; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Code</a>
          <a href="javascript:void(0)" onclick="document.getElementById('Cancer2024_bib').style.display = document.getElementById('Cancer2024_bib').style.display === 'none' ? 'block' : 'none';" style="background-color: #8b5cf6; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Citation bib</a>
        </div>
      </li>
    </ul>
    <div id="Cancer2024_bib" class="bib" style="display:none; font-family: 'Segoe UI', sans-serif; color: black; margin-top: 10px;">
      <pre>
@misc{moin2024exploringexplainableaitechniques,
  title={Exploring Explainable AI Techniques for Improved Interpretability in Lung and Colon Cancer Classification},
  author={Mukaffi Bin Moin and Fatema Tuj Johora Faria and Swarnajit Saha and Busra Kamal Rafa and Mohammad Shafiul Alam},
  year={2024},
  eprint={2405.07340},
  archivePrefix={arXiv},
  primaryClass={eess.IV},
  url={https://arxiv.org/abs/2405.07340},
}
      </pre>
    </div>
    <div id="Cancer2024_abstract" class="abstract" style="display:none; font-family: 'Segoe UI', sans-serif; color: black; margin-top: 10px;">
      <p style="text-align: justify;">
        Accurate classification of lung and colon cancer from medical images is critical for early diagnosis and effective treatment. However, deep learning models often operate as black boxes, making their decisions difficult to interpret. This study explores explainable AI (XAI) techniques to enhance the interpretability of convolutional neural network (CNN) models for lung and colon cancer classification. We evaluate multiple pre-trained CNN architectures, including ResNet50, VGG16, and DenseNet121, on a dataset of histopathological images. XAI methods such as Grad-CAM, Grad-CAM++, and SHAP are applied to highlight regions of interest and explain model predictions. Our results show that DenseNet121 achieves the highest classification accuracy of 92.78%, while Grad-CAM++ provides the most precise visualization of critical image regions. The integration of XAI improves model transparency, with a 5.12% increase in trust metrics among medical professionals surveyed. This work demonstrates the potential of XAI in making deep learning models more interpretable and reliable for clinical applications.
      </p>
    </div>
  </div>
</div>

<h2>2023</h2>
<hr>
<div style="display: flex; flex-wrap: wrap; gap: 20px;">
  <div style="background-color: white; border-left: 5px solid #3b82f6; border-radius: 10px; padding: 25px; flex: 1 1 100%; max-width: 100%; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); transition: transform 0.2s ease, box-shadow 0.2s ease;" onmouseover="this.style.transform='scale(1.01)'; this.style.boxShadow='0 5px 10px rgba(0, 0, 0, 0.12)';" onmouseout="this.style.transform='scale(1)'; this.style.boxShadow='0 4px 6px rgba(0, 0, 0, 0.1)';">
    <div style="background-color: #dbeafe; padding: 10px; border-radius: 5px; margin-bottom: 15px;">
      <span style="color: #1e3a8a; font-size: 1em; font-weight: bold;">Vashantor: A Large-scale Multilingual Benchmark Dataset for Automated Translation of Bangla Regional Dialects to Bangla Language</span>
    </div>
    <ul style="font-family: 'Segoe UI', sans-serif; color: black; margin-top: 15px;">
      <li style="margin-bottom: 12px; list-style-type: none; position: relative; padding-left: 25px;">
        <span style="position: absolute; left: 0; color: #3b82f6; font-size: 0.9em;">■</span>
        <b>Authors:</b> <span style="color: #10b981">Fatema Tuj Johora Faria</span>, Mukaffi Bin Moin, Ahmed Al Wase, Mehidi Ahmmed, Md Rabius Sani, and Tashreef Muhammad <br/>
        <b>Journal:</b> <em>Under Review in Neural Computing and Applications</em> <span style="background-color: #e6f4ea; color: #3b82f6; padding: 2px 8px; border-radius: 4px; font-size: 0.9em;">Q1</span> <br/>
        <div style="margin-top: 10px;">
          <a href="javascript:void(0)" onclick="document.getElementById('Vashantor2023_abstract').style.display = document.getElementById('Vashantor2023_abstract').style.display === 'none' ? 'block' : 'none';" style="background-color: #3b82f6; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Abstract</a>
          <a href="https://arxiv.org/pdf/2305.07341" style="background-color: #ef4444; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">PDF</a>
          <a href="https://github.com/fatemafaria142/Vashantor-A-Large-scale-Multilingual-Benchmark-Dataset" style="background-color: #10b981; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Code</a>
          <a href="https://data.mendeley.com/datasets/vashantor_dataset" style="background-color: #f59e0b; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Dataset</a>
          <a href="javascript:void(0)" onclick="document.getElementById('Vashantor2023_bib').style.display = document.getElementById('Vashantor2023_bib').style.display === 'none' ? 'block' : 'none';" style="background-color: #8b5cf6; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Citation bib</a>
        </div>
      </li>
    </ul>
    <div id="Vashantor2023_bib" class="bib" style="display: none; font-family: 'Segoe UI', sans-serif; color: black; margin-top: 10px;">
      <pre>
@misc{faria2023vashantorlargescalemultilingualbenchmark,
  title={Vashantor: A Large-scale Multilingual Benchmark Dataset for Automated Translation of Bangla Regional Dialects to Bangla Language},
  author={Fatema Tuj Johora Faria and Mukaffi Bin Moin and Ahmed Al Wase and Mehidi Ahmmed and Md Rabius Sani and Tashreef Muhammad},
  year={2023},
  eprint={2305.07341},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2305.07341},
}
      </pre>
    </div>
    <div id="Vashantor2023_abstract" class="abstract" style="display: none; font-family: 'Segoe UI', sans-serif; color: black; margin-top: 10px;">
      <p style="text-align: justify;">
        Bangla, a low-resource language, exhibits rich linguistic diversity with multiple regional dialects, posing challenges for automated translation systems. This study introduces Vashantor, a large-scale multilingual benchmark dataset for translating Bangla regional dialects to standard Bangla. The dataset comprises 12,000 sentence pairs across five major dialects: Chittagonian, Sylheti, Barisal, Noakhali, and Dhaka. We evaluate state-of-the-art models, including Transformer-based architectures like mBART and NLLB, and large language models like GPT-3.5 Turbo. Our results show that NLLB achieves the highest BLEU score of 32.45, while GPT-3.5 Turbo excels in contextual accuracy with a 78.23% translation quality score in few-shot settings. The dataset addresses the scarcity of resources for Bangla dialect translation, enabling robust model training and evaluation. This work facilitates advancements in multilingual NLP for low-resource languages.
      </p>
    </div>
  </div>

  <div style="background-color: white; border-left: 5px solid #ef4444; border-radius: 10px; padding: 25px; flex: 1 1 100%; max-width: 100%; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); transition: transform 0.2s ease, box-shadow 0.2s ease;" onmouseover="this.style.transform='scale(1.01)'; this.style.boxShadow='0 5px 10px rgba(0, 0, 0, 0.12)';" onmouseout="this.style.transform='scale(1)'; this.style.boxShadow='0 4px 6px rgba(0, 0, 0, 0.1)';">
    <div style="background-color: #fee2e2; padding: 10px; border-radius: 5px; margin-bottom: 15px;">
      <span style="color: #7f1d1d; font-size: 1em; font-weight: bold;">Classification of Potato Disease with Digital Image Processing Technique: A Hybrid Deep Learning Framework</span>
    </div>
    <ul style="font-family: 'Segoe UI', sans-serif; color: black; margin-top: 15px;">
      <li style="margin-bottom: 12px; list-style-type: none; position: relative; padding-left: 25px;">
        <span style="position: absolute; left: 0; color: #ef4444; font-size: 0.9em;">■</span>
        <b>Authors:</b> <span style="color: #10b981">Fatema Tuj Johora Faria</span>, Mukaffi Bin Moin, Ahmed Al Wase, Md Rabius Sani, Khan Md Hasib, and Mohammad Shafiul Alam <br/>
        <b>Conference:</b> <em>2023 IEEE 13th Annual Computing and Communication Workshop and Conference (CCWC)</em> <br/>
        <div style="margin-top: 10px;">
          <a href="javascript:void(0)" onclick="document.getElementById('Potato2023_abstract').style.display = document.getElementById('Potato2023_abstract').style.display === 'none' ? 'block' : 'none';" style="background-color: #3b82f6; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Abstract</a>
          <a href="https://ieeexplore.ieee.org/document/10099215" style="background-color: #ef4444; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">PDF</a>
          <a href="https://github.com/fatemafaria142/Potato-Disease-Classification" style="background-color: #10b981; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Code</a>
          <a href="https://data.mendeley.com/datasets/potato_disease_dataset" style="background-color: #f59e0b; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; margin-right: 5px; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Dataset</a>
          <a href="javascript:void(0)" onclick="document.getElementById('Potato2023_bib').style.display = document.getElementById('Potato2023_bib').style.display === 'none' ? 'block' : 'none';" style="background-color: #8b5cf6; color: white; padding: 4px 8px; border-radius: 5px; text-decoration: none; transition: transform 0.2s ease;" onmouseover="this.style.transform='scale(1.05)';" onmouseout="this.style.transform='scale(1)';">Citation bib</a>
        </div>
      </li>
    </ul>
    <div id="Potato2023_bib" class="bib" style="display: none; font-family: 'Segoe UI', sans-serif; color: black; margin-top: 10px;">
      <pre>
@INPROCEEDINGS{10099215,
  author={Faria, Fatema Tuj Johora and Moin, Mukaffi Bin and Al Wase, Ahmed and Sani, Md Rabius and Hasib, Khan Md and Alam, Mohammad Shafiul},
  booktitle={2023 IEEE 13th Annual Computing and Communication Workshop and Conference (CCWC)},
  title={Classification of Potato Disease with Digital Image Processing Technique: A Hybrid Deep Learning Framework},
  year={2023},
  volume={},
  number={},
  pages={0554-0560},
  doi={10.1109/CCWC57344.2023.10099215}
}
      </pre>
    </div>
    <div id="Potato2023_abstract" class="abstract" style="display: none; font-family: 'Segoe UI', sans-serif; color: black; margin-top: 10px;">
      <p style="text-align: justify;">
        Potato diseases significantly impact agricultural yields, necessitating accurate and timely identification for effective crop management. This study proposes a hybrid deep learning framework for potato disease classification using digital image processing techniques. We utilize a dataset of 5,000 potato leaf images, annotated for diseases such as late blight, early blight, and bacterial wilt. The framework combines convolutional neural networks (CNNs) like ResNet50 and VGG16 with image preprocessing techniques, including histogram equalization and edge detection. Our hybrid model achieves a classification accuracy of 89.34%, outperforming traditional machine learning methods by 7.21%. The study also incorporates data augmentation to enhance model robustness, addressing challenges like varying lighting conditions and image quality. This work provides a scalable solution for automated potato disease detection, supporting farmers in low-resource settings.
      </p>
    </div>
  </div>
</div>